{"cells":[{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2475,"status":"ok","timestamp":1642085322364,"user":{"displayName":"Assaf La","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggg7DEAOambuBZkmwZ_9nyzKIhOJ9xl0skw55KG490=s64","userId":"07226046456222457646"},"user_tz":-120},"id":"OMIVlc1Bg_4M","outputId":"5619caaa-28ad-487c-a236-813318477b95"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31,"status":"ok","timestamp":1642085322366,"user":{"displayName":"Assaf La","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggg7DEAOambuBZkmwZ_9nyzKIhOJ9xl0skw55KG490=s64","userId":"07226046456222457646"},"user_tz":-120},"id":"ZMRxQXMsRamB","outputId":"1788131f-d100-42ce-d258-968d2b7f53d3"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/afeka/Project/code/PTEEnet/PTEEnet\n"]}],"source":["#@title cd\n","%pwd\n","%cd /content/drive/MyDrive/afeka/Project/code/PTEEnet/PTEEnet"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5143,"status":"ok","timestamp":1642085327493,"user":{"displayName":"Assaf La","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggg7DEAOambuBZkmwZ_9nyzKIhOJ9xl0skw55KG490=s64","userId":"07226046456222457646"},"user_tz":-120},"id":"UVXtOWnTB_MB","outputId":"52da0c31-57e2-437a-b3c6-75f625bfe0ca"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: chainer in /usr/local/lib/python3.7/dist-packages (7.8.1)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from chainer) (1.15.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from chainer) (3.4.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from chainer) (3.10.0.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from chainer) (57.4.0)\n","Requirement already satisfied: protobuf>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from chainer) (3.17.3)\n","Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from chainer) (1.19.5)\n"]}],"source":["#@title install packages\n","%pip install chainer\n","%pip install -Uqq ipdb"]},{"cell_type":"code","execution_count":37,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":452,"status":"ok","timestamp":1642085327936,"user":{"displayName":"Assaf La","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggg7DEAOambuBZkmwZ_9nyzKIhOJ9xl0skw55KG490=s64","userId":"07226046456222457646"},"user_tz":-120},"id":"fOMPfWSZhFlH","outputId":"c14bfc25-6241-42ab-d34b-28d66953f29c"},"outputs":[{"output_type":"stream","name":"stdout","text":["GPU availability: True\n","cuDNN availablility: True\n","Thu Jan 13 14:48:47 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   39C    P0    35W / 250W |   1023MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n","Your runtime has 27.3 gigabytes of available RAM\n","\n","You are using a high-RAM runtime!\n"]}],"source":["#@title read gpu details\n","import chainer\n","#chainer.print_runtime_info()\n","\n","print('GPU availability:', chainer.cuda.available)\n","print('cuDNN availablility:', chainer.cuda.cudnn_enabled)\n","gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n","  print('and then re-execute this cell.')\n","else:\n","  print(gpu_info)\n","\n","from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n","  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n","  print('re-execute this cell.')\n","else:\n","  print('You are using a high-RAM runtime!')"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"YxxBGSa5UqrP","cellView":"form","executionInfo":{"status":"ok","timestamp":1642085327937,"user_tz":-120,"elapsed":29,"user":{"displayName":"Assaf La","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggg7DEAOambuBZkmwZ_9nyzKIhOJ9xl0skw55KG490=s64","userId":"07226046456222457646"}}},"outputs":[],"source":["#@title imports\n","\"\"\"\n","high level support for doing this and that.\n","\"\"\"\n","from __future__ import print_function\n","import time\n","import csv\n","import numpy as np\n","import torch\n","import torch.nn.functional as F\n","from scipy import stats\n","from init import initializer\n","from eenet import EENet\n","from custom_eenet import CustomEENet\n","from gatednet import GatedNet\n","import matplotlib.pylab as plt\n","import loss_functions\n","import utils\n","import config\n","import gc\n","import sys\n","import math\n","import os\n","from torch.utils.tensorboard import SummaryWriter\n","import torchvision.transforms.functional as tf\n","import matplotlib.pyplot as plt\n","import ipdb\n","\n","import xgboost as xgb\n","from sklearn.metrics import confusion_matrix, classification_report\n","from sklearn.metrics import accuracy_score\n","import joblib as jobl\n","from collections import Counter\n","from matplotlib import pyplot\n","from numpy import where\n","from imblearn.over_sampling import RandomOverSampler \n","from imblearn.under_sampling import RandomUnderSampler\n","from imblearn.over_sampling import SMOTE\n","from sklearn.model_selection import train_test_split\n","from xgboost.sklearn import XGBRegressor\n","\n","%matplotlib inline\n"]},{"cell_type":"code","execution_count":39,"metadata":{"cellView":"form","id":"WVgJ_onrXSUZ","executionInfo":{"status":"ok","timestamp":1642085327938,"user_tz":-120,"elapsed":28,"user":{"displayName":"Assaf La","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggg7DEAOambuBZkmwZ_9nyzKIhOJ9xl0skw55KG490=s64","userId":"07226046456222457646"}}},"outputs":[],"source":["#@title plot_ee_histogram\n","def plot_ee_histogram(args, val_confs, type_loader, dir):\n","    %matplotlib inline\n","    x_pos = np.arange(args.num_ee+1)\n","    #print(x_pos)\n","    print(val_confs)\n","    bar = plt.bar(x_pos, val_confs, align='center')\n","    plt.xlabel('Exit number')\n","    plt.ylabel('# of Samples in Exit')\n","    plt.title(args.dataset + ' samples distribution in exits using ' + args.model + \n","              ' model\\n' + 'SNR=' + str(args.noise_snr) + 'dB')\n","    plt.ylim(0, max(val_confs))\n","    plt.savefig(dir + '/ee_hist_' + type_loader + '.' + str(args.loss_threshold) + '.png')\n","    plt.show()\n","    "]},{"cell_type":"code","execution_count":40,"metadata":{"cellView":"form","id":"GHyuN338603H","executionInfo":{"status":"ok","timestamp":1642085327939,"user_tz":-120,"elapsed":27,"user":{"displayName":"Assaf La","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggg7DEAOambuBZkmwZ_9nyzKIhOJ9xl0skw55KG490=s64","userId":"07226046456222457646"}}},"outputs":[],"source":["#@title plot_noise_exits\n","import plotly.graph_objects as go\n","import matplotlib\n","\n","#@title plot_noise_exits\n","def plot_noise_exits_box(args, type_loader):\n","    %matplotlib inline\n","    x_pos = np.arange(args.num_noise_levels)\n","\n","    for thresh in range(1, 13, 1):\n","        loss_threshold = thresh/10\n","        data_file = args.relative_losses_dir + '/noise_exits_' + type_loader + '.' + str(loss_threshold) + '.pt'\n","        noise_exits = torch.load(data_file)\n","        #noise_exits = np.array(noise_exits)\n","\n","        #ipdb.set_trace(context=6)\n","        mean=np.mean(noise_exits,axis=1)\n","        print(mean)\n","\n","        fig, ax = plt.subplots()#figure(figsize =(10, 7))\n","    \n","        # Creating axes instance\n","        ax.set_title(args.dataset + ' samples distribution in exits using ' + args.model + ' with threshold=' + str(loss_threshold))\n","        ax.set_xlabel('noise index')\n","        ax.set_ylabel('# exits')\n","        \n","        # Creating plot\n","        bp = ax.boxplot(noise_exits)\n","        \n","        # show plot\n","        plt.show()\n","        plt.savefig(args.relative_losses_dir + '/bp_noises_exits_' + '.' + str(loss_threshold) + '.png')\n","        \n","def plot_noise_exits_scatter(args, type_loader):\n","    %matplotlib inline\n","    #x_pos = np.arange(args.num_noise_levels)\n","    noise_levels = np.arange(args.min_noise_snr, args.max_noise_snr,\n","        (args.max_noise_snr - args.min_noise_snr)/args.num_noise_levels) \n","\n","    x = noise_levels\n","    selected_losses = np.array([0.3, 0.5, 0.7, 0.9])\n","    colors = ['green', 'black', 'red', 'blue']\n","    fig = go.Figure()\n","\n","    #for thresh in selected_losses:\n","    for idx, thresh in enumerate(selected_losses):\n","        loss_threshold = thresh#/10\n","        data_file = args.relative_losses_dir + '/noise_exits_' + type_loader + '.' + str(loss_threshold) + '.pt'\n","        data = torch.load(data_file)\n","        #noises_data.append(data)\n","\n","        #mean=np.median(data,axis=1)\n","        mean=np.mean(data,axis=1)\n","        std=np.std(data,axis=1)\n","        q1=np.quantile(data,q=0.25,axis=1)\n","        q3=np.quantile(data,q=0.75,axis=1)\n","        \"\"\"\n","        fig = go.Figure()\n","        \n","        fig.add_trace(go.Scatter(x=x, y=q3,\n","                                mode='lines',\n","                                line=dict(color='red',width =0.1),\n","                                name='upper bound'))\n","        \"\"\"\n","        fig.add_trace(go.Scatter(x=x, y=mean,\n","                                mode='lines',\n","                                line=dict(color=colors[idx]),\n","                                #fill='tonexty',\n","                                name='threshold ' + str(loss_threshold)))\n","        \"\"\"\n","        fig.add_trace(go.Scatter(x=x, y=q1,\n","                                mode='lines',\n","                                line=dict(color='blue', width =0.1),\n","                                fill='tonexty',\n","                                name='lower bound'))\n","        \"\"\"\n","        #ipdb.set_trace(context=6)\n","    fig.update_layout(\n","        title=args.dataset + ' samples distribution in exits using ' + args.model,# + ' with threshold=' + str(loss_threshold),\n","        xaxis_title=\"noise level in SNR (dB)\",\n","        yaxis_title=\"# exit\",\n","        xaxis = dict(\n","            tickmode = 'array',\n","            tickvals = noise_levels,\n","        ),\n","        width=700,\n","        height=500)\n","\n","    #plt.show()\n","    fig.show()\n","    plt.savefig(args.relative_losses_dir + '/bp_noises_exits_' + '.' + str(args.loss_threshold) + '.png')"]},{"cell_type":"code","execution_count":41,"metadata":{"cellView":"form","id":"WCarzY5EGFlc","executionInfo":{"status":"ok","timestamp":1642085327940,"user_tz":-120,"elapsed":26,"user":{"displayName":"Assaf La","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggg7DEAOambuBZkmwZ_9nyzKIhOJ9xl0skw55KG490=s64","userId":"07226046456222457646"}}},"outputs":[],"source":["#@title exit_flow_analysis\n","def exit_flow_analysis(args, model, val_loader):\n","    \"\"\"examine the model output.\n","    Arguments are\n","    * args:         command line arguments entered by user.\n","    * model:        convolutional neural network model.\n","    * train_loader: train data loader.\n","    This examines the outputs of already trained model.\n","    \"\"\"\n","    model.eval()\n","    val_confs_true = []\n","    val_confs_false = []\n","    vals_len_true = np.zeros(args.num_ee+1)\n","    vals_len_false = np.zeros(args.num_ee+1)\n","    for i in range(args.num_ee+1):\n","        val_confs_true.append([])\n","        val_confs_false.append([])\n","    \n","    #val_confs[0].append('aa2')\n","    #val_confs = np.empty((args.num_ee, 0), float)#np.zeros(len(val_loader.dataset))\n","    #i = 0\n","    \"\"\"\n","    print(args.results_dir+'/pred_vs_conf.csv')\n","    experiment = open(args.results_dir+'/pred_vs_conf.csv', 'w', newline='')\n","    recorder = csv.writer(experiment, delimiter=',')\n","    recorder.writerow(['target',\n","                       'start_pred_seq',\n","                       'start_conf_seq',\n","                       'start_exit_seq',\n","                       'actual_pred',\n","                       'actual_conf',\n","                       'actual_exit'])\n","    \"\"\"\n","    \n","    print('add noise w/ SNR=' + str(args.testing_snr) + 'dB')\n","    \n","    with torch.no_grad():\n","        for data, target in val_loader:\n","            data = add_noise(args, data)\n","            \n","            data, target = data.to(args.device), target.to(args.device, dtype=torch.int64)\n","            pred, conf, cost, idx = model(data)\n","            loss = F.nll_loss(pred.log(), target)\n","\n","            pred = pred.max(1, keepdim=True)[1].item()\n","            conf = conf.item()\n","            #print(loss)\n","            #conf = torch.max(confs).item()\n","            #i += 1\n","            #confs = [c.item() for c in confs]\n","            loss = loss.item()\n","            target = target.item()\n","            if target == pred:\n","                val_confs_true[idx].append(conf)\n","            else:\n","                val_confs_false[idx].append(conf)\n","\n","            #val_confs[idx].append(conf)\n","\n","    total_correct = 0\n","    for i in range(args.num_ee+1):\n","        total_correct += len(val_confs_true[i])\n","        if len(val_confs_true[i]) > 1:\n","            filename = 'test_true_confs_hist_ee' + str(i)\n","            vals_len_true[i] = len(val_confs_true[i])\n","            utils.plot_histogram(args, val_confs_true[i], 'conf', 100, filename, saveplot=True)\n","        if len(val_confs_false[i]) > 1:\n","            filename = 'test_false_confs_hist_ee' + str(i)\n","            vals_len_false[i] = len(val_confs_false[i])\n","            utils.plot_histogram(args, val_confs_false[i], 'conf', 100, filename, saveplot=True)\n","    flat_list_true = [item for sublist in val_confs_true for item in sublist]\n","    flat_list_false = [item for sublist in val_confs_false for item in sublist]\n","    \n","    utils.plot_histogram(args, flat_list_true, 'conf true', 100, 'global_conf_true', saveplot=True)\n","    utils.plot_histogram(args, flat_list_false, 'conf false', 100, 'global_conf_false', saveplot=True)\n","    print('total currect: ', total_correct)\n","    print('total acc : ', total_correct * 100 /10000)\n","    plot_ee_histogram(args, vals_len_true)\n","    plot_ee_histogram(args, vals_len_false)\n","    return"]},{"cell_type":"code","execution_count":42,"metadata":{"cellView":"code","id":"M0FWfwVdGNma","executionInfo":{"status":"ok","timestamp":1642085327941,"user_tz":-120,"elapsed":24,"user":{"displayName":"Assaf La","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggg7DEAOambuBZkmwZ_9nyzKIhOJ9xl0skw55KG490=s64","userId":"07226046456222457646"}}},"outputs":[],"source":["#@title Train\n","def train(args, model, train_loader, optimizer):\n","    \"\"\"train the model.\n","\n","    Arguments are\n","    * args:         command line arguments entered by user.\n","    * model:        convolutional neural network model.\n","    * train_loader: train data loader.\n","    * optimizer:    optimize the model during training.\n","    * epoch:        epoch number.\n","\n","    This trains the model and prints the results of each epochs.\n","    \"\"\"\n","    losses = []\n","    pred_losses = []\n","    cost_losses = []\n","    model.train()\n","    \n","    # actual training starts\n","    #for batch_id, ((data, noise), target) in enumerate(train_loader):\n","    for batch_id, (data, target) in enumerate(train_loader):\n","        # fetch the current batch data\n","        data, target = data.to(args.device), target.to(args.device, dtype=torch.int64)\n","        exit_tag = None\n","        optimizer.zero_grad()\n","        cum_loss = 0\n","        cost = []\n","\n","        # training settings for EENet based models\n","        if isinstance(model, (CustomEENet, EENet)):\n","            pred, conf = model(data)\n","            #ipdb.set_trace(context=6)\n","            cost.append(1)#torch.tensor(1.0).to(args.device))\n","            \n","            if args.use_main_targets:\n","                _, target = torch.max(pred[args.num_ee], 1)\n","                         \n","            cum_loss, pred_loss, cost_loss = loss_functions.loss(args, exit_tag, pred, target, conf, cost)\n","            \n","        # training settings for other models\n","        else:\n","            pred = model(data)\n","            cum_loss = F.cross_entropy(pred, target)\n","\n","        losses.append(float(cum_loss))\n","        pred_losses.append(float(pred_loss))\n","        cost_losses.append(float(cost_loss))\n","        cum_loss.backward()\n","        optimizer.step()\n","        \"\"\"\n","        for obj in gc.get_objects():\n","            try:\n","                if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):\n","                    print(type(obj), obj.size())\n","            except:\n","                pass\n","        \"\"\"\n","        #print(model.exits[1].classifier[0].weight)\n","\n","        # update the exit tags of inputs\n","    #print(pred_loss)\n","    #print('target')\n","    #print(target)\n","    \n","    # print the training results of epoch\n","    result = {'train_loss': round(np.mean(losses), 4),\n","              'train_loss_sem': round(stats.sem(losses), 2),\n","              'pred_loss': round(np.mean(pred_losses), 4),\n","              'pred_loss_sem': round(stats.sem(pred_losses), 2),\n","              'cost_loss': round(np.mean(cost_losses), 4),\n","              'cost_loss_sem': round(stats.sem(cost_losses), 2)}\n","\n","    print('Train avg loss: {:.4f}'.format(result['train_loss']))\n","    \n","    return result"]},{"cell_type":"code","execution_count":43,"metadata":{"cellView":"code","id":"_RxrxOmgGRto","executionInfo":{"status":"ok","timestamp":1642085327942,"user_tz":-120,"elapsed":24,"user":{"displayName":"Assaf La","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggg7DEAOambuBZkmwZ_9nyzKIhOJ9xl0skw55KG490=s64","userId":"07226046456222457646"}}},"outputs":[],"source":["#@title Validate\n","\n","def accuracy(output, target, topk=(1,)):\n","    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n","    maxk = max(topk)\n","    batch_size = target.size(0)\n","\n","    _, pred = output.topk(maxk, 1, True, True)\n","    pred = pred.t()\n","    correct = pred.eq(target.view(1, -1).expand_as(pred))\n","\n","    res = []\n","    for k in topk:\n","        correct_k = correct[:k].view(-1).float().sum(0)\n","        res.append(correct_k.mul_(100.0 / batch_size))\n","    return res\n","\n","def validate(args, model, val_loader):\n","    batch = {'time':[], 'cost':[], 'flop':[], 'acc':[], 'val_loss':[]}\n","    exit_points = [0]*(args.num_ee+1)\n","    # switch to evaluate mode\n","    model.eval()\n","    main_ee_losses = []\n","        \n","    with torch.no_grad():\n","        \n","        for batch_id, (data, target) in enumerate(val_loader):\n","            batch_size = target.shape[0]        \n","            data, target = data.to(args.device), target.to(args.device, dtype=torch.int64)\n","            # compute output\n","            start = time.process_time()\n","\n","            # results of EENet based models\n","            if isinstance(model, (EENet, CustomEENet)):                \n","                preds, confs = model(data)\n","                \n","                if args.use_main_targets:\n","                    _, target = torch.max(preds[args.num_ee], 1)                \n","        \n","                if mode == Mode.train_main:\n","                    pred = preds[args.num_ee]\n","                    cost = 1\n","                    exit_points[args.num_ee] += batch_size\n","                    flop = model.complexity[-1][0]\n","                    pred_loss = F.nll_loss(pred.log(), target)\n","                    main_ee_losses.append(float(main_ee_loss))\n","                    \n","                elif mode == Mode.train_ee:\n","                    losses = []\n","                    costs = []\n","                    flops = []\n","\n","                    pred_losses = torch.empty((args.num_ee + 1, batch_size), dtype=torch.float)\n","                    pred = torch.zeros((batch_size, preds[0].shape[1]), dtype=torch.float, device = 'cuda')\n","                    \n","                    for i in range(args.num_ee+1):\n","                        cost = model.complexity[i][0]/model.complexity[-1][0]\n","                        pred_losses[i] = F.nll_loss(preds[i].log(), target, reduction='none') +\\\n","                                args.lambda_coef * cost\n","                    main_ee_loss = F.nll_loss(preds[args.num_ee].log(), target)\n","                    main_ee_losses.append(float(main_ee_loss))\n","                    \n","                    for j in range(batch_size):\n","                        best_exit = args.num_ee\n","                        for i in range(args.num_ee):    \n","                            if pred_losses[i][j] < args.loss_threshold:\n","                                best_exit = i\n","                                break\n","                        \n","                        #ipdb.set_trace(context=3)\n","                        exit_points[best_exit] += 1\n","                        best_pred_loss = pred_losses[best_exit][j]\n","                        losses.append(float(best_pred_loss))\n","                        cost = model.complexity[best_exit][0]/model.complexity[-1][0] \n","                        flop = model.complexity[best_exit][0]\n","                        flops.append(float(flop))\n","                        costs.append(float(cost))\n","                        pred[j] = preds[best_exit][j]\n","                    \n","                    #ipdb.set_trace(context=3)\n","                    cost = round(np.mean(costs), 4)\n","                    pred_loss = round(np.mean(losses), 4)\n","                    flop = round(np.mean(flops), 4)\n","                    #ipdb.set_trace(context=3)                    \n","                    losses = None\n","                    costs = None\n","                    flops = None                    \n","                else:\n","                    print('Unknown mode')\n","                    \n","            elapsed_time = time.process_time() - start\n","            prec1 = accuracy(pred.float().data, target)[0]\n","            pred = None\n","                \n","            batch['acc'].append(float(prec1))\n","            batch['time'].append(elapsed_time)\n","            batch['cost'].append(cost*100.)\n","            batch['flop'].append(flop)\n","            batch['val_loss'].append(float(pred_loss))\n","            \n","    print('main ee avg loss: ', round(np.mean(main_ee_losses), 4))\n","    utils.print_validation(args, batch, exit_points)\n","    \n","    result = {}\n","    for key, value in batch.items():\n","        result[key] = round(np.mean(value), 4)\n","        result[key+'_sem'] = round(stats.sem(value), 2)\n","    \n","    result['exit_points'] = exit_points\n","    return result\n"]},{"cell_type":"code","execution_count":44,"metadata":{"id":"UTyGwEMtGWT4","executionInfo":{"status":"ok","timestamp":1642085327943,"user_tz":-120,"elapsed":23,"user":{"displayName":"Assaf La","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggg7DEAOambuBZkmwZ_9nyzKIhOJ9xl0skw55KG490=s64","userId":"07226046456222457646"}},"cellView":"code"},"outputs":[],"source":["#@title run()\n","def run(model, optimizer, lr_scheduler, args, train_loader, test_loader):\n","    # best = {}\n","    # best_epoch = 0\n","    \n","    print('Running for {:5d} epochs'.format(args.epochs))\n","    try:\n","        if not args.no_tensorboard:\n","            writer = SummaryWriter('../runs/train_eenet_experiment_1')\n","        torch.cuda.empty_cache()\n","        for epoch in range(args.start_epoch, args.epochs + 1):\n","            print('{:3d}:'.format(epoch), end='')\n","\n","            # two-stage training uses the loss version-1 after training for 25 epochs\n","            if args.two_stage and epoch > 25:\n","                args.loss_func = \"v1\"\n","            \n","            result = {'epoch':epoch}\n","            \n","            result.update(train(args, model, train_loader, optimizer))\n","            if not args.no_tensorboard:\n","                writer.add_scalar(\"Train/loss\", result['train_loss'], epoch)\n","\n","            # use adaptive learning rate\n","            if args.adaptive_lr:\n","                lr_scheduler.step()\n","\n","            # validate and keep history at each log interval\n","            if epoch % args.log_interval == 0:\n","                result.update(validate(args, model, test_loader))\n","                utils.save_history(args, result)\n","                if not args.no_tensorboard:\n","                    writer.add_scalar(\"Val/loss\", result['val_loss'], epoch)\n","                    writer.add_scalars('Val/acc_cost', {\n","                        'acc': result['acc'],\n","                        'cost': result['cost']\n","                    }, epoch)\n","            if not args.no_tensorboard:    \n","                writer.flush()\n","            # save model parameters\n","            if not args.no_save_model:\n","                utils.save_model(args, model, epoch)\n","    except KeyboardInterrupt:\n","        utils.close_history(args)\n","        utils.plot_history(args)\n","        if not args.no_tensorboard:\n","            writer.close()\n","        sys.exit()\n","    # print the best validation result\n","    best_epoch = utils.close_history(args)\n","\n","    # save the model giving the best validation results as a final model\n","    if args.save_best:\n","        utils.save_model(args, model, best_epoch, True)\n","    utils.plot_history(args)\n","    if not args.no_tensorboard:\n","        writer.close()\n"]},{"cell_type":"code","execution_count":45,"metadata":{"cellView":"form","id":"6cWNwDHcGa8Y","executionInfo":{"status":"ok","timestamp":1642085327944,"user_tz":-120,"elapsed":23,"user":{"displayName":"Assaf La","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggg7DEAOambuBZkmwZ_9nyzKIhOJ9xl0skw55KG490=s64","userId":"07226046456222457646"}}},"outputs":[],"source":["#@title enable_branches_training_only\n","def enable_branches_training_only(model, args):\n","    if args.model == 'eenet8':\n","        model.set_ee_disable(False)\n","        model.initblock.requires_grad_(False)\n","        model.basicblock1.requires_grad_(False)\n","        model.basicblock2.requires_grad_(False)\n","        model.basicblock3.requires_grad_(False)\n","        model.finalblock.requires_grad_(False)\n","        model.classifier.requires_grad_(False)\n","        model.conv2d_6.requires_grad_(False)\n","        model.conv2d_9.requires_grad_(False)\n","    else:\n","        model.set_ee_disable(False)\n","        for idx, exitblock in enumerate(model.exits):\n","            model.stages[idx].requires_grad_(False)\n","            for param in model.exits.parameters():\n","                param.requires_grad = True\n","            #model.exits.requires_grad(True)\n","\n","        model.stages[-1].requires_grad_(False)\n","        model.classifier.requires_grad_(False)\n","        model.confidence.requires_grad_(False)\n","        \n","        #params = model_post.state_dict()\n","        #print(params)\n","        \n","        \"\"\"\n","        ipdb.set_trace(context=3)\n","        for name, p in model.named_parameters():\n","            if p.requires_grad:\n","                print(name, p.requires_grad)\n","        \"\"\"\n","                "]},{"cell_type":"code","execution_count":46,"metadata":{"id":"9SaYNXpxXzhT","cellView":"code","executionInfo":{"status":"ok","timestamp":1642085327949,"user_tz":-120,"elapsed":27,"user":{"displayName":"Assaf La","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggg7DEAOambuBZkmwZ_9nyzKIhOJ9xl0skw55KG490=s64","userId":"07226046456222457646"}}},"outputs":[],"source":["#@title load data\n","from torch.utils.data import Dataset, TensorDataset, DataLoader\n","\n","class CustomTensorDataset(Dataset):\n","    \"\"\"TensorDataset with support of transforms.\n","    \"\"\"\n","    def __init__(self, tensors, transform=None):\n","        #ipdb.set_trace(context=6)\n","        assert all(tensors[0].size(0) == tensor.size(0) for tensor in tensors)\n","        self.tensors = tensors\n","        self.transform = transform\n","\n","    def __getitem__(self, index):\n","        x = self.tensors[0][index]\n","\n","        if self.transform:\n","            x = self.transform(x)\n","\n","        y = self.tensors[1][index]\n","        \n","        return x, y\n","\n","    def __len__(self):\n","        return self.tensors[0].size(0)\n","        \n","#def load_data(args):\n","#    return utils.load_custom_dataset(args)\n","\n","def load_data(args):\n","    serialized_data_dir = 'serialized_data'\n","    \n","    data_file_train = serialized_data_dir + '/datas_train' + '.pt'\n","    data_train = torch.load(data_file_train)\n","    print('loaded data train at: ', data_file_train)\n","    \n","    data_file_test = serialized_data_dir + '/datas_test' + '.pt'\n","    data_test = torch.load(data_file_test)\n","    print('loaded data test at: ', data_file_test)\n","    \n","    gt_file_train = serialized_data_dir + '/targets_train' + '.pt'\n","    target_train = torch.load(gt_file_train)\n","    print('loaded exits ground truths train at: ', gt_file_train)\n","    \n","    gt_file_test = serialized_data_dir + '/targets_test' + '.pt'\n","    target_test = torch.load(gt_file_test)\n","    print('loaded exits ground truths test at: ', gt_file_test)\n","\n","    data_train, data_test, target_train, target_test = train_test_split(data_train,\\\n","                                                                        target_train, test_size=0.33, random_state=42)\n","    \n","    data_train, target_train = torch.from_numpy(data_train), torch.from_numpy(target_train)    \n","    data_test, target_test = torch.from_numpy(data_test), torch.from_numpy(target_test)\n","    \n","    train_set = CustomTensorDataset(tensors=(data_train, target_train))    \n","    validation_set = CustomTensorDataset(tensors=(data_test, target_test))\n","    loader_train = torch.utils.data.DataLoader(train_set, batch_size=args.batch_size, shuffle=args.shuffle_train)\n","    loader_val = torch.utils.data.DataLoader(validation_set, batch_size=args.test_batch, shuffle=args.shuffle_test)\n","\n","    return loader_train, loader_val"]},{"cell_type":"code","execution_count":47,"metadata":{"executionInfo":{"elapsed":26,"status":"ok","timestamp":1642085327950,"user":{"displayName":"Assaf La","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggg7DEAOambuBZkmwZ_9nyzKIhOJ9xl0skw55KG490=s64","userId":"07226046456222457646"},"user_tz":-120},"id":"TiAPblzAGeLz","colab":{"base_uri":"https://localhost:8080/"},"cellView":"code","outputId":"4361b16b-f1a1-42e8-cdc7-d6551449f448"},"outputs":[{"output_type":"stream","name":"stdout","text":["The autoreload extension is already loaded. To reload it, use:\n","  %reload_ext autoreload\n"]}],"source":["#@title main\n","\n","\"\"\"Main function of the program.\n","\n","The function loads the dataset and calls training and validation functions.\n","\"\"\"\n","%load_ext autoreload\n","%autoreload 2\n","\n","import importlib\n","importlib.reload(config)\n","importlib.reload(loss_functions)\n","importlib.reload(utils)\n","#from eenet import EENet\n","#from gatednet import GatedNet, GatedNetS\n","from enum import Enum\n","\n","class Mode(Enum):\n","    train_main = 0\n","    train_ee = 1\n","    generate_exits_gt = 2 \n","    train_gating = 3\n","    generate_relative_loss = 4 \n","    plot_relative_loss = 5\n","    calc_relative_time = 6\n","\n","def main(mode: Mode):\n","    print(mode.value)\n","    args = config.args_global\n","    args += config.argu[mode.value]\n","    \n","    print(args)\n","    %pwd\n","    model, optimizer, lr_scheduler, args = initializer(args)\n","    \n","    if mode == Mode.train_main:\n","        train_loader, test_loader, exit_tags, trainset, testset = load_data(args)\n","        model.set_ee_disable(True)\n","        print('Disabled EE branches')\n","        run(model, optimizer, lr_scheduler, args, train_loader, test_loader, exit_tags)\n","    elif mode == Mode.train_ee:\n","        #train_loader, test_loader, exit_tags, trainset, testset = load_data(args)\n","        train_loader, test_loader = load_data(args)\n","        enable_branches_training_only(model, args)\n","        print('Enabled EE branches')\n","        print('loss threshold: ', args.loss_threshold)\n","        run(model, optimizer, lr_scheduler, args, train_loader, test_loader)\n","    \n","    print('Finished')"]},{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":882722,"status":"ok","timestamp":1642086210651,"user":{"displayName":"Assaf La","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggg7DEAOambuBZkmwZ_9nyzKIhOJ9xl0skw55KG490=s64","userId":"07226046456222457646"},"user_tz":-120},"id":"v9gjbi-OCQ2J","outputId":"9b97880d-6ee9-435f-beef-5c21ccbc32f2"},"outputs":[{"output_type":"stream","name":"stdout","text":["1\n","['--dataset', 'cifar10', '--model', 'eenet110', '--num-ee', '10', '--filters', '4', '--exit-type', 'conv2', '--distribution', 'fine', '--min-noise-snr', '-5', '--max-noise-snr', '30', '--num-noise-levels', '5', '--validate', '--epochs', '50', '--lambda-coef', '0.0', '--optimizer', 'Adam', '--lr', '0.001', '--weight-decay', '0.0001', '--load-model', 'models/cifar10/eenet110/UT/clean/after_main_training/model.pt', '--use-main-targets', '--loss-func', 'v0', '--no-tensorboard', '--clear-dirs', '--batch-size', '128', '--test-batch', '128', '--log-interval', '1', '--loss-threshold', '0.2', '--shuffle-train']\n","use cuda:  True  device:  cuda\n","empty model loaded at:  models/cifar10/eenet110/UT/clean/after_main_training/model.pt\n","ee-block-0: flops=19.78 MMac, params=19.34 k, cost-rate=0.08\n","ee-block-1: flops=34.23 MMac, params=33.35 k, cost-rate=0.13\n","ee-block-2: flops=43.86 MMac, params=42.7 k, cost-rate=0.17\n","ee-block-3: flops=53.49 MMac, params=52.04 k, cost-rate=0.21\n","ee-block-4: flops=63.13 MMac, params=61.39 k, cost-rate=0.25\n","ee-block-5: flops=72.76 MMac, params=70.73 k, cost-rate=0.28\n","ee-block-6: flops=82.4 MMac, params=80.08 k, cost-rate=0.32\n","ee-block-7: flops=92.03 MMac, params=89.42 k, cost-rate=0.36\n","ee-block-8: flops=100.48 MMac, params=136.57 k, cost-rate=0.39\n","ee-block-9: flops=110.01 MMac, params=173.69 k, cost-rate=0.43\n","exit-block: flops=256.32 MMac, params=1.73 M, cost-rate=1.00\n","loaded data train at:  serialized_data/datas_train.pt\n","loaded data test at:  serialized_data/datas_test.pt\n","loaded exits ground truths train at:  serialized_data/targets_train.pt\n","loaded exits ground truths test at:  serialized_data/targets_test.pt\n","Enabled EE branches\n","loss threshold:  0.2\n","Running for    50 epochs\n","  1:Train avg loss: 19.5036\n","main ee avg loss:  0.0782\n","     Test avg time: 4.0770msec; avg val_loss: 0.0806; avg val_acc: 100.00%\n","\tavg val_cost: 98.73%; exits: <0,0,0,0,0,0,0,0,250,30,12920,>\n","saving model:  ../models/cifar10/eenet110/ee10_fine_conv2_lambda_0.0/model.v1.pt\n","  2:Train avg loss: 15.7184\n","main ee avg loss:  0.0756\n","     Test avg time: 4.0641msec; avg val_loss: 0.0962; avg val_acc: 100.00%\n","\tavg val_cost: 89.43%; exits: <9,70,8,1,12,3,0,3,1439,769,10886,>\n","saving model:  ../models/cifar10/eenet110/ee10_fine_conv2_lambda_0.0/model.v2.pt\n","  3:Train avg loss: 14.0295\n","main ee avg loss:  0.078\n","     Test avg time: 4.0730msec; avg val_loss: 0.1068; avg val_acc: 100.00%\n","\tavg val_cost: 83.39%; exits: <53,1,23,0,20,10,10,2,2331,1196,9554,>\n","saving model:  ../models/cifar10/eenet110/ee10_fine_conv2_lambda_0.0/model.v3.pt\n","  4:Train avg loss: 13.0676\n","main ee avg loss:  0.0768\n","     Test avg time: 4.0583msec; avg val_loss: 0.1069; avg val_acc: 100.00%\n","\tavg val_cost: 80.02%; exits: <138,12,17,4,47,7,14,26,2986,1069,8880,>\n","saving model:  ../models/cifar10/eenet110/ee10_fine_conv2_lambda_0.0/model.v4.pt\n","  5:Train avg loss: 12.3653\n","main ee avg loss:  0.0768\n","     Test avg time: 4.0471msec; avg val_loss: 0.1143; avg val_acc: 100.00%\n","\tavg val_cost: 74.72%; exits: <134,79,106,59,49,49,33,159,3498,1230,7804,>\n","saving model:  ../models/cifar10/eenet110/ee10_fine_conv2_lambda_0.0/model.v5.pt\n","  6:Train avg loss: 11.8346\n","main ee avg loss:  0.0778\n","     Test avg time: 4.0298msec; avg val_loss: 0.1176; avg val_acc: 100.00%\n","\tavg val_cost: 71.80%; exits: <198,37,85,99,108,78,48,141,3908,1299,7199,>\n","saving model:  ../models/cifar10/eenet110/ee10_fine_conv2_lambda_0.0/model.v6.pt\n","  7:Train avg loss: 11.4270\n","main ee avg loss:  0.0772\n","     Test avg time: 4.0546msec; avg val_loss: 0.1173; avg val_acc: 100.00%\n","\tavg val_cost: 69.79%; exits: <265,84,104,113,158,109,46,267,3811,1400,6843,>\n","saving model:  ../models/cifar10/eenet110/ee10_fine_conv2_lambda_0.0/model.v7.pt\n","  8:Train avg loss: 11.1386\n","main ee avg loss:  0.0768\n","     Test avg time: 4.0296msec; avg val_loss: 0.1189; avg val_acc: 100.00%\n","\tavg val_cost: 67.66%; exits: <259,139,129,135,115,140,56,188,4138,1488,6413,>\n","saving model:  ../models/cifar10/eenet110/ee10_fine_conv2_lambda_0.0/model.v8.pt\n","  9:Train avg loss: 10.8876\n","main ee avg loss:  0.0782\n","     Test avg time: 4.0202msec; avg val_loss: 0.1227; avg val_acc: 100.00%\n","\tavg val_cost: 65.04%; exits: <296,146,252,259,273,275,77,180,4021,1408,6013,>\n","saving model:  ../models/cifar10/eenet110/ee10_fine_conv2_lambda_0.0/model.v9.pt\n"," 10:Train avg loss: 10.6845\n","main ee avg loss:  0.0764\n","     Test avg time: 3.9860msec; avg val_loss: 0.1236; avg val_acc: 100.00%\n","\tavg val_cost: 63.18%; exits: <464,361,210,306,294,266,86,178,3810,1441,5784,>\n","saving model:  ../models/cifar10/eenet110/ee10_fine_conv2_lambda_0.0/model.v10.pt\n"," 11:Train avg loss: 10.4994\n","main ee avg loss:  0.0767\n","     Test avg time: 3.9657msec; avg val_loss: 0.1243; avg val_acc: 100.00%\n","\tavg val_cost: 60.90%; exits: <530,160,331,440,359,310,161,166,3942,1451,5350,>\n","saving model:  ../models/cifar10/eenet110/ee10_fine_conv2_lambda_0.0/model.v11.pt\n"," 12:Train avg loss: 10.3346\n","main ee avg loss:  0.0769\n","     Test avg time: 3.9541msec; avg val_loss: 0.1262; avg val_acc: 100.00%\n","\tavg val_cost: 61.12%; exits: <547,240,420,268,443,284,267,206,3715,1352,5458,>\n","saving model:  ../models/cifar10/eenet110/ee10_fine_conv2_lambda_0.0/model.v12.pt\n"," 13:Train avg loss: 10.1928\n","main ee avg loss:  0.0766\n","     Test avg time: 3.9559msec; avg val_loss: 0.1255; avg val_acc: 100.00%\n","\tavg val_cost: 59.35%; exits: <604,295,483,449,306,218,138,236,3931,1394,5146,>\n","saving model:  ../models/cifar10/eenet110/ee10_fine_conv2_lambda_0.0/model.v13.pt\n"," 14:Train avg loss: 10.0815\n","main ee avg loss:  0.0757\n","     Test avg time: 3.9306msec; avg val_loss: 0.1235; avg val_acc: 100.00%\n","\tavg val_cost: 59.07%; exits: <887,345,369,483,294,241,100,194,3712,1362,5213,>\n","saving model:  ../models/cifar10/eenet110/ee10_fine_conv2_lambda_0.0/model.v14.pt\n"," 15:Train avg loss: 9.9901\n","main ee avg loss:  0.0777\n","     Test avg time: 3.9223msec; avg val_loss: 0.1271; avg val_acc: 100.00%\n","\tavg val_cost: 56.50%; exits: <1043,257,488,511,332,219,124,338,3704,1405,4779,>\n","saving model:  ../models/cifar10/eenet110/ee10_fine_conv2_lambda_0.0/model.v15.pt\n"," 16:Train avg loss: 9.8745\n","main ee avg loss:  0.0767\n","     Test avg time: 3.9153msec; avg val_loss: 0.1280; avg val_acc: 100.00%\n","\tavg val_cost: 56.97%; exits: <815,420,495,588,270,225,166,308,3814,1238,4861,>\n","saving model:  ../models/cifar10/eenet110/ee10_fine_conv2_lambda_0.0/model.v16.pt\n"," 17:Train avg loss: 9.8155\n","main ee avg loss:  0.0762\n","     Test avg time: 3.9405msec; avg val_loss: 0.1267; avg val_acc: 100.00%\n","\tavg val_cost: 56.27%; exits: <993,490,550,372,297,236,164,169,3800,1366,4763,>\n","saving model:  ../models/cifar10/eenet110/ee10_fine_conv2_lambda_0.0/model.v17.pt\n"," 18:Train avg loss: 9.6874\n","main ee avg loss:  0.0756\n","     Test avg time: 3.9209msec; avg val_loss: 0.1261; avg val_acc: 100.00%\n","\tavg val_cost: 55.80%; exits: <945,479,638,345,322,288,272,244,3521,1463,4683,>\n","saving model:  ../models/cifar10/eenet110/ee10_fine_conv2_lambda_0.0/model.v18.pt\n"," 19:Train avg loss: 9.6210\n","main ee avg loss:  0.0768\n","     Test avg time: 3.9285msec; avg val_loss: 0.1229; avg val_acc: 100.00%\n","\tavg val_cost: 57.00%; exits: <803,454,460,478,262,235,198,172,3965,1364,4809,>\n","saving model:  ../models/cifar10/eenet110/ee10_fine_conv2_lambda_0.0/model.v19.pt\n"," 20:Train avg loss: 9.5473\n","main ee avg loss:  0.0779\n","     Test avg time: 3.9146msec; avg val_loss: 0.1282; avg val_acc: 100.00%\n","\tavg val_cost: 55.64%; exits: <892,536,505,561,297,377,247,285,3620,1189,4691,>\n","saving model:  ../models/cifar10/eenet110/ee10_fine_conv2_lambda_0.0/model.v20.pt\n"," 21:Train avg loss: 9.4956\n","main ee avg loss:  0.0757\n","     Test avg time: 3.8923msec; avg val_loss: 0.1272; avg val_acc: 100.00%\n","\tavg val_cost: 53.32%; exits: <1469,441,468,395,341,303,293,332,3593,1186,4379,>\n","saving model:  ../models/cifar10/eenet110/ee10_fine_conv2_lambda_0.0/model.v21.pt\n"," 22:Train avg loss: 9.4240\n","main ee avg loss:  0.0777\n","     Test avg time: 3.9132msec; avg val_loss: 0.1291; avg val_acc: 100.00%\n","\tavg val_cost: 53.40%; exits: <1158,601,593,576,297,257,215,222,3519,1401,4361,>\n","saving model:  ../models/cifar10/eenet110/ee10_fine_conv2_lambda_0.0/model.v22.pt\n"," 23:Train avg loss: 9.3594\n","main ee avg loss:  0.0766\n","     Test avg time: 3.9282msec; avg val_loss: 0.1273; avg val_acc: 100.00%\n","\tavg val_cost: 54.54%; exits: <1008,438,392,530,322,249,398,350,3710,1393,4410,>\n","saving model:  ../models/cifar10/eenet110/ee10_fine_conv2_lambda_0.0/model.v23.pt\n"," 24:Train avg loss: 9.3376\n","main ee avg loss:  0.0773\n","     Test avg time: 3.9025msec; avg val_loss: 0.1261; avg val_acc: 100.00%\n","\tavg val_cost: 52.75%; exits: <1149,856,644,357,285,213,171,174,3743,1341,4267,>\n","saving model:  ../models/cifar10/eenet110/ee10_fine_conv2_lambda_0.0/model.v24.pt\n"," 25:Train avg loss: 9.2649\n","main ee avg loss:  0.0781\n","     Test avg time: 3.8788msec; avg val_loss: 0.1282; avg val_acc: 100.00%\n","\tavg val_cost: 51.81%; exits: <1341,624,668,387,340,253,312,248,3587,1297,4143,>\n","saving model:  ../models/cifar10/eenet110/ee10_fine_conv2_lambda_0.0/model.v25.pt\n"," 26:Train avg loss: 9.2178\n","main ee avg loss:  0.078\n","     Test avg time: 3.8989msec; avg val_loss: 0.1256; avg val_acc: 100.00%\n","\tavg val_cost: 51.98%; exits: <1408,522,754,244,334,324,245,219,3860,1128,4162,>\n","saving model:  ../models/cifar10/eenet110/ee10_fine_conv2_lambda_0.0/model.v26.pt\n"," 27:Train avg loss: 9.2131\n","main ee avg loss:  0.0782\n","     Test avg time: 3.9025msec; avg val_loss: 0.1250; avg val_acc: 100.00%\n","\tavg val_cost: 54.49%; exits: <955,902,587,405,328,268,158,287,3638,1076,4596,>\n","saving model:  ../models/cifar10/eenet110/ee10_fine_conv2_lambda_0.0/model.v27.pt\n"," 28:Train avg loss: 9.1416\n","main ee avg loss:  0.0771\n","     Test avg time: 3.8585msec; avg val_loss: 0.1265; avg val_acc: 100.00%\n","\tavg val_cost: 50.23%; exits: <1770,824,503,498,397,192,219,204,3371,1161,4061,>\n","saving model:  ../models/cifar10/eenet110/ee10_fine_conv2_lambda_0.0/model.v28.pt\n"," 29:Train avg loss: 9.0848\n","main ee avg loss:  0.0764\n","     Test avg time: 3.8601msec; avg val_loss: 0.1250; avg val_acc: 100.00%\n","\tavg val_cost: 50.27%; exits: <1538,1068,532,289,321,374,173,200,3485,1216,4004,>\n","saving model:  ../models/cifar10/eenet110/ee10_fine_conv2_lambda_0.0/model.v29.pt\n"," 30:Train avg loss: 9.0677\n","main ee avg loss:  0.0768\n","     Test avg time: 3.9084msec; avg val_loss: 0.1239; avg val_acc: 100.00%\n","\tavg val_cost: 51.88%; exits: <1224,1016,329,429,254,296,206,265,3638,1449,4094,>\n","saving model:  ../models/cifar10/eenet110/ee10_fine_conv2_lambda_0.0/model.v30.pt\n"," 31:Train avg loss: 9.0281\n","main ee avg loss:  0.0772\n","     Test avg time: 3.8860msec; avg val_loss: 0.1261; avg val_acc: 100.00%\n","\tavg val_cost: 50.47%; exits: <1568,707,629,449,330,273,260,215,3602,1171,3996,>\n","saving model:  ../models/cifar10/eenet110/ee10_fine_conv2_lambda_0.0/model.v31.pt\n"," 32:Train avg loss: 8.9803\n","main ee avg loss:  0.0767\n","     Test avg time: 3.8905msec; avg val_loss: 0.1243; avg val_acc: 100.00%\n","\tavg val_cost: 50.63%; exits: <1364,886,397,321,357,414,422,244,3604,1272,3919,>\n","saving model:  ../models/cifar10/eenet110/ee10_fine_conv2_lambda_0.0/model.v32.pt\n"," 33:Train avg loss: 8.9913\n","main ee avg loss:  0.0784\n","     Test avg time: 3.8834msec; avg val_loss: 0.1273; avg val_acc: 100.00%\n","\tavg val_cost: 50.25%; exits: <1342,1031,507,413,310,312,355,255,3564,1190,3921,>\n","saving model:  ../models/cifar10/eenet110/ee10_fine_conv2_lambda_0.0/model.v33.pt\n"," 34:Train avg loss: 8.9666\n","main ee avg loss:  0.0773\n","     Test avg time: 3.8751msec; avg val_loss: 0.1249; avg val_acc: 100.00%\n","\tavg val_cost: 49.03%; exits: <1830,532,550,412,591,293,159,278,3583,1221,3751,>\n","saving model:  ../models/cifar10/eenet110/ee10_fine_conv2_lambda_0.0/model.v34.pt\n"," 35:Train avg loss: 8.9028\n","main ee avg loss:  0.0777\n","     Test avg time: 3.8586msec; avg val_loss: 0.1276; avg val_acc: 100.00%\n","\tavg val_cost: 49.05%; exits: <1833,849,587,307,417,319,224,271,3304,1223,3866,>\n","saving model:  ../models/cifar10/eenet110/ee10_fine_conv2_lambda_0.0/model.v35.pt\n"," 36:Train avg loss: 8.8955\n","main ee avg loss:  0.0775\n","     Test avg time: 3.8713msec; avg val_loss: 0.1206; avg val_acc: 100.00%\n","\tavg val_cost: 50.38%; exits: <1511,913,374,438,305,214,199,176,4000,1154,3916,>\n","saving model:  ../models/cifar10/eenet110/ee10_fine_conv2_lambda_0.0/model.v36.pt\n"," 37:Train avg loss: 8.8505\n","main ee avg loss:  0.0767\n","     Test avg time: 3.8485msec; avg val_loss: 0.1264; avg val_acc: 100.00%\n","\tavg val_cost: 49.04%; exits: <1530,986,672,321,325,416,290,372,3393,1094,3801,>\n","saving model:  ../models/cifar10/eenet110/ee10_fine_conv2_lambda_0.0/model.v37.pt\n"," 38:Train avg loss: 8.7812\n","main ee avg loss:  0.0785\n","     Test avg time: 3.8720msec; avg val_loss: 0.1275; avg val_acc: 100.00%\n","\tavg val_cost: 49.48%; exits: <1371,958,482,475,400,408,264,241,3486,1357,3758,>\n","saving model:  ../models/cifar10/eenet110/ee10_fine_conv2_lambda_0.0/model.v38.pt\n"," 39:Train avg loss: 8.7502\n","main ee avg loss:  0.0776\n","     Test avg time: 3.8619msec; avg val_loss: 0.1237; avg val_acc: 100.00%\n","\tavg val_cost: 48.46%; exits: <2070,732,477,368,337,302,290,202,3401,1267,3754,>\n","saving model:  ../models/cifar10/eenet110/ee10_fine_conv2_lambda_0.0/model.v39.pt\n"," 40:Train avg loss: 8.7397\n","main ee avg loss:  0.0777\n","     Test avg time: 3.8643msec; avg val_loss: 0.1251; avg val_acc: 100.00%\n","\tavg val_cost: 48.28%; exits: <1519,1174,505,340,281,581,237,287,3442,1178,3656,>\n","saving model:  ../models/cifar10/eenet110/ee10_fine_conv2_lambda_0.0/model.v40.pt\n"," 41:Train avg loss: 8.7403\n","main ee avg loss:  0.0754\n","     Test avg time: 3.8551msec; avg val_loss: 0.1251; avg val_acc: 100.00%\n","\tavg val_cost: 47.50%; exits: <1897,925,643,427,321,245,246,274,3451,1165,3606,>\n","saving model:  ../models/cifar10/eenet110/ee10_fine_conv2_lambda_0.0/model.v41.pt\n"," 42:Train avg loss: 8.7152\n","main ee avg loss:  0.0772\n","     Test avg time: 3.8741msec; avg val_loss: 0.1251; avg val_acc: 100.00%\n","\tavg val_cost: 49.48%; exits: <1346,821,849,457,333,356,278,316,3431,1212,3801,>\n","saving model:  ../models/cifar10/eenet110/ee10_fine_conv2_lambda_0.0/model.v42.pt\n"," 43:Train avg loss: 8.6560\n","main ee avg loss:  0.0786\n","     Test avg time: 3.8372msec; avg val_loss: 0.1241; avg val_acc: 100.00%\n","\tavg val_cost: 47.71%; exits: <2049,951,487,348,421,252,334,225,3253,1173,3707,>\n","saving model:  ../models/cifar10/eenet110/ee10_fine_conv2_lambda_0.0/model.v43.pt\n"," 44:Train avg loss: 8.6783\n","main ee avg loss:  0.0773\n","     Test avg time: 3.8888msec; avg val_loss: 0.1239; avg val_acc: 100.00%\n","\tavg val_cost: 48.35%; exits: <1427,700,728,618,351,410,297,301,3534,1256,3578,>\n","saving model:  ../models/cifar10/eenet110/ee10_fine_conv2_lambda_0.0/model.v44.pt\n"," 45:Train avg loss: 8.6722\n","main ee avg loss:  0.0775\n","     Test avg time: 3.8581msec; avg val_loss: 0.1260; avg val_acc: 100.00%\n","\tavg val_cost: 47.20%; exits: <1893,898,524,705,398,250,206,242,3441,1066,3577,>\n","saving model:  ../models/cifar10/eenet110/ee10_fine_conv2_lambda_0.0/model.v45.pt\n"," 46:Train avg loss: 8.6300\n","main ee avg loss:  0.0775\n","     Test avg time: 3.8475msec; avg val_loss: 0.1238; avg val_acc: 100.00%\n","\tavg val_cost: 47.29%; exits: <2006,778,656,523,231,365,214,208,3556,1084,3579,>\n","saving model:  ../models/cifar10/eenet110/ee10_fine_conv2_lambda_0.0/model.v46.pt\n"," 47:Train avg loss: 8.6126\n","main ee avg loss:  0.0766\n","     Test avg time: 3.8506msec; avg val_loss: 0.1212; avg val_acc: 100.00%\n","\tavg val_cost: 47.15%; exits: <1945,796,681,402,354,444,268,171,3421,1163,3555,>\n","saving model:  ../models/cifar10/eenet110/ee10_fine_conv2_lambda_0.0/model.v47.pt\n"," 48:Train avg loss: 8.5790\n","main ee avg loss:  0.0767\n","     Test avg time: 3.8586msec; avg val_loss: 0.1242; avg val_acc: 100.00%\n","\tavg val_cost: 47.03%; exits: <1373,1073,791,651,379,312,244,298,3471,1159,3449,>\n","saving model:  ../models/cifar10/eenet110/ee10_fine_conv2_lambda_0.0/model.v48.pt\n"," 49:Train avg loss: 8.5726\n","main ee avg loss:  0.0766\n","     Test avg time: 3.8452msec; avg val_loss: 0.1249; avg val_acc: 100.00%\n","\tavg val_cost: 46.71%; exits: <1951,927,684,433,284,296,239,226,3496,1175,3489,>\n","saving model:  ../models/cifar10/eenet110/ee10_fine_conv2_lambda_0.0/model.v49.pt\n"," 50:Train avg loss: 8.5492\n","main ee avg loss:  0.0764\n","     Test avg time: 3.8354msec; avg val_loss: 0.1251; avg val_acc: 100.00%\n","\tavg val_cost: 46.79%; exits: <1934,830,775,438,307,385,357,352,3085,1232,3505,>\n","saving model:  ../models/cifar10/eenet110/ee10_fine_conv2_lambda_0.0/model.v50.pt\n","\n","The best avg val_loss: 0.0806, avg val_cost: 98.7275%, avg val_acc: 100.0%\n","\n","The figure is plotted under '../results/cifar10/eenet110/ee10_fine_conv2_lambda_0.0/loss_figure.png'\n","The figure is plotted under '../results/cifar10/eenet110/ee10_fine_conv2_lambda_0.0/acc_cost_figure.png'\n","The figure is plotted under '../results/cifar10/eenet110/ee10_fine_conv2_lambda_0.0/rel_acc_vs_cost_figure.png'\n","The figure is plotted under '../results/cifar10/eenet110/ee10_fine_conv2_lambda_0.0/acc_vs_flop_figure.png'\n","Finished\n"]}],"source":["mode = Mode.train_ee\n","main(mode)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"colab_resnet_train.ipynb","provenance":[]},"interpreter":{"hash":"31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"},"kernelspec":{"display_name":"Python 3.7.12 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"metadata":{"interpreter":{"hash":"4cd7ab41f5fca4b9b44701077e38c5ffd31fe66a6cab21e0214b68d958d0e462"}}},"nbformat":4,"nbformat_minor":0}
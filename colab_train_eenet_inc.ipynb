{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2174,"status":"ok","timestamp":1648113009985,"user":{"displayName":"Assaf La","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUaXBQVi1i3pv_IG6dyzlsX7aSwxWMcT_iQuRs8no=s64","userId":"07226046456222457646"},"user_tz":-120},"id":"OMIVlc1Bg_4M","outputId":"bea80fd6-ee16-4c76-82f7-78f912954735"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1648113009986,"user":{"displayName":"Assaf La","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUaXBQVi1i3pv_IG6dyzlsX7aSwxWMcT_iQuRs8no=s64","userId":"07226046456222457646"},"user_tz":-120},"id":"ZMRxQXMsRamB","outputId":"904c4b45-4649-43ac-9a50-08ce67381514"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/afeka/Project/code/PTEEnet/PTEEnet\n"]}],"source":["#@title cd\n","%pwd\n","%cd /content/drive/MyDrive/afeka/Project/code/PTEEnet/PTEEnet"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"UwsZgBbZypCh","executionInfo":{"status":"ok","timestamp":1648113009987,"user_tz":-120,"elapsed":10,"user":{"displayName":"Assaf La","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUaXBQVi1i3pv_IG6dyzlsX7aSwxWMcT_iQuRs8no=s64","userId":"07226046456222457646"}},"cellView":"form"},"outputs":[],"source":["#@title font\n","\n","def decrease_font():\n","  from IPython.display import Javascript\n","  display(Javascript('''\n","  for (rule of document.styleSheets[0].cssRules){\n","    if (rule.selectorText=='body') {\n","      rule.style.fontSize = '12px'\n","      break\n","    }\n","  }\n","  '''))\n","get_ipython().events.register('pre_run_cell', decrease_font)"]},{"cell_type":"code","execution_count":4,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/","height":148},"executionInfo":{"elapsed":6347,"status":"ok","timestamp":1648113016325,"user":{"displayName":"Assaf La","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUaXBQVi1i3pv_IG6dyzlsX7aSwxWMcT_iQuRs8no=s64","userId":"07226046456222457646"},"user_tz":-120},"id":"UVXtOWnTB_MB","outputId":"e383da15-0cc2-45b9-cee3-098a4a83b727"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","  for (rule of document.styleSheets[0].cssRules){\n","    if (rule.selectorText=='body') {\n","      rule.style.fontSize = '12px'\n","      break\n","    }\n","  }\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: chainer in /usr/local/lib/python3.7/dist-packages (7.8.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from chainer) (57.4.0)\n","Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from chainer) (1.21.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from chainer) (3.10.0.2)\n","Requirement already satisfied: protobuf>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from chainer) (3.17.3)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from chainer) (1.15.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from chainer) (3.6.0)\n"]}],"source":["#@title install packages\n","%pip install chainer\n","%pip install -Uqq ipdb"]},{"cell_type":"code","execution_count":5,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/","height":589},"executionInfo":{"elapsed":1555,"status":"ok","timestamp":1648113017865,"user":{"displayName":"Assaf La","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUaXBQVi1i3pv_IG6dyzlsX7aSwxWMcT_iQuRs8no=s64","userId":"07226046456222457646"},"user_tz":-120},"id":"fOMPfWSZhFlH","outputId":"8e000a69-ef40-4424-f516-12938f0aea8a"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","  for (rule of document.styleSheets[0].cssRules){\n","    if (rule.selectorText=='body') {\n","      rule.style.fontSize = '12px'\n","      break\n","    }\n","  }\n","  "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/chainer/_environment_check.py:75: UserWarning: \n","--------------------------------------------------------------------------------\n","CuPy (cupy-cuda111) version 9.4.0 may not be compatible with this version of Chainer.\n","Please consider installing the supported version by running:\n","  $ pip install 'cupy-cuda111>=7.7.0,<8.0.0'\n","\n","See the following page for more details:\n","  https://docs.cupy.dev/en/latest/install.html\n","--------------------------------------------------------------------------------\n","\n","  requirement=requirement, help=help))\n"]},{"output_type":"stream","name":"stdout","text":["GPU availability: True\n","cuDNN availablility: True\n","Thu Mar 24 09:10:17 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   38C    P0    26W / 250W |      2MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n","Your runtime has 27.3 gigabytes of available RAM\n","\n","You are using a high-RAM runtime!\n"]}],"source":["#@title read gpu details\n","import chainer\n","#chainer.print_runtime_info()\n","\n","print('GPU availability:', chainer.cuda.available)\n","print('cuDNN availablility:', chainer.cuda.cudnn_enabled)\n","gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n","  print('and then re-execute this cell.')\n","else:\n","  print(gpu_info)\n","\n","from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n","  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n","  print('re-execute this cell.')\n","else:\n","  print('You are using a high-RAM runtime!')"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":1287,"status":"ok","timestamp":1648113019528,"user":{"displayName":"Assaf La","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUaXBQVi1i3pv_IG6dyzlsX7aSwxWMcT_iQuRs8no=s64","userId":"07226046456222457646"},"user_tz":-120},"id":"YxxBGSa5UqrP","outputId":"4878d3b7-3272-4266-be36-b34e86a74803","cellView":"form"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","  for (rule of document.styleSheets[0].cssRules){\n","    if (rule.selectorText=='body') {\n","      rule.style.fontSize = '12px'\n","      break\n","    }\n","  }\n","  "]},"metadata":{}}],"source":["#@title imports\n","\"\"\"\n","high level support for doing this and that.\n","\"\"\"\n","from __future__ import print_function\n","import time\n","import csv\n","import numpy as np\n","import torch\n","import torch.nn.functional as F\n","from scipy import stats\n","from init import initializer\n","from eenet import EENet\n","from custom_eenet import CustomEENet\n","from gatednet import GatedNet\n","import matplotlib.pylab as plt\n","import loss_functions\n","from early_stopping import early_stop\n","import utils\n","import config\n","import gc\n","import sys\n","import math\n","import os\n","from torch.utils.tensorboard import SummaryWriter\n","import torchvision.transforms.functional as tf\n","import matplotlib.pyplot as plt\n","import ipdb\n","import shutil\n","\n","#import xgboost as xgb\n","#from sklearn.metrics import confusion_matrix, classification_report\n","#from sklearn.metrics import accuracy_score\n","#import joblib as jobl\n","#from collections import Counter\n","from matplotlib import pyplot\n","from numpy import where\n","#from imblearn.over_sampling import RandomOverSampler \n","#from imblearn.under_sampling import RandomUnderSampler\n","#from imblearn.over_sampling import SMOTE\n","from sklearn.model_selection import train_test_split\n","#from xgboost.sklearn import XGBRegressor\n","\n","%matplotlib inline\n"]},{"cell_type":"code","execution_count":7,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":37,"status":"ok","timestamp":1648113019529,"user":{"displayName":"Assaf La","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUaXBQVi1i3pv_IG6dyzlsX7aSwxWMcT_iQuRs8no=s64","userId":"07226046456222457646"},"user_tz":-120},"id":"WVgJ_onrXSUZ","outputId":"05b88520-9a18-4305-a631-020b8476261c"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","  for (rule of document.styleSheets[0].cssRules){\n","    if (rule.selectorText=='body') {\n","      rule.style.fontSize = '12px'\n","      break\n","    }\n","  }\n","  "]},"metadata":{}}],"source":["#@title plot_ee_histogram\n","def plot_ee_histogram(args, val_confs, type_loader, dir):\n","    %matplotlib inline\n","    x_pos = np.arange(args.num_ee+1)\n","    #print(x_pos)\n","    print(val_confs)\n","    bar = plt.bar(x_pos, val_confs, align='center')\n","    plt.xlabel('Exit number')\n","    plt.ylabel('# of Samples in Exit')\n","    plt.title(args.dataset + ' samples distribution in exits using ' + args.model + \n","              ' model\\n' + 'SNR=' + str(args.noise_snr) + 'dB')\n","    plt.ylim(0, max(val_confs))\n","    plt.savefig(dir + '/ee_hist_' + type_loader + '.' + str(args.loss_threshold) + '.png')\n","    plt.show()\n","    "]},{"cell_type":"code","execution_count":8,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":34,"status":"ok","timestamp":1648113019529,"user":{"displayName":"Assaf La","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUaXBQVi1i3pv_IG6dyzlsX7aSwxWMcT_iQuRs8no=s64","userId":"07226046456222457646"},"user_tz":-120},"id":"WCarzY5EGFlc","outputId":"a7bd76b7-e34e-4a7c-fe00-26fed31303da"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","  for (rule of document.styleSheets[0].cssRules){\n","    if (rule.selectorText=='body') {\n","      rule.style.fontSize = '12px'\n","      break\n","    }\n","  }\n","  "]},"metadata":{}}],"source":["#@title exit_flow_analysis\n","def exit_flow_analysis(args, model, val_loader):\n","    \"\"\"examine the model output.\n","    Arguments are\n","    * args:         command line arguments entered by user.\n","    * model:        convolutional neural network model.\n","    * train_loader: train data loader.\n","    This examines the outputs of already trained model.\n","    \"\"\"\n","    model.eval()\n","    val_confs_true = []\n","    val_confs_false = []\n","    vals_len_true = np.zeros(args.num_ee+1)\n","    vals_len_false = np.zeros(args.num_ee+1)\n","    for i in range(args.num_ee+1):\n","        val_confs_true.append([])\n","        val_confs_false.append([])\n","    \n","    #val_confs[0].append('aa2')\n","    #val_confs = np.empty((args.num_ee, 0), float)#np.zeros(len(val_loader.dataset))\n","    #i = 0\n","    \"\"\"\n","    print(args.results_dir+'/pred_vs_conf.csv')\n","    experiment = open(args.results_dir+'/pred_vs_conf.csv', 'w', newline='')\n","    recorder = csv.writer(experiment, delimiter=',')\n","    recorder.writerow(['target',\n","                       'start_pred_seq',\n","                       'start_conf_seq',\n","                       'start_exit_seq',\n","                       'actual_pred',\n","                       'actual_conf',\n","                       'actual_exit'])\n","    \"\"\"\n","    \n","    print('add noise w/ SNR=' + str(args.testing_snr) + 'dB')\n","    \n","    with torch.no_grad():\n","        for data, target in val_loader:\n","            data = add_noise(args, data)\n","            \n","            data, target = data.to(args.device), target.to(args.device, dtype=torch.int64)\n","            pred, conf, cost, idx = model(data)\n","            loss = F.nll_loss(pred.log(), target)\n","\n","            pred = pred.max(1, keepdim=True)[1].item()\n","            conf = conf.item()\n","            #print(loss)\n","            #conf = torch.max(confs).item()\n","            #i += 1\n","            #confs = [c.item() for c in confs]\n","            loss = loss.item()\n","            target = target.item()\n","            if target == pred:\n","                val_confs_true[idx].append(conf)\n","            else:\n","                val_confs_false[idx].append(conf)\n","\n","            #val_confs[idx].append(conf)\n","\n","    total_correct = 0\n","    for i in range(args.num_ee+1):\n","        total_correct += len(val_confs_true[i])\n","        if len(val_confs_true[i]) > 1:\n","            filename = 'test_true_confs_hist_ee' + str(i)\n","            vals_len_true[i] = len(val_confs_true[i])\n","            utils.plot_histogram(args, val_confs_true[i], 'conf', 100, filename, saveplot=True)\n","        if len(val_confs_false[i]) > 1:\n","            filename = 'test_false_confs_hist_ee' + str(i)\n","            vals_len_false[i] = len(val_confs_false[i])\n","            utils.plot_histogram(args, val_confs_false[i], 'conf', 100, filename, saveplot=True)\n","    flat_list_true = [item for sublist in val_confs_true for item in sublist]\n","    flat_list_false = [item for sublist in val_confs_false for item in sublist]\n","    \n","    utils.plot_histogram(args, flat_list_true, 'conf true', 100, 'global_conf_true', saveplot=True)\n","    utils.plot_histogram(args, flat_list_false, 'conf false', 100, 'global_conf_false', saveplot=True)\n","    print('total currect: ', total_correct)\n","    print('total acc : ', total_correct * 100 /10000)\n","    plot_ee_histogram(args, vals_len_true)\n","    plot_ee_histogram(args, vals_len_false)\n","    return"]},{"cell_type":"code","source":["#@title print_require_grads_only\n","def print_require_grads_only(model):\n","    #ipdb.set_trace(context=3)\n","    for name, p in model.named_parameters():\n","        if p.requires_grad:\n","            print(\"!!!!: \", name, p.requires_grad)\n","        #else:\n","        #    print(name, p.requires_grad)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"cellView":"form","id":"KYjuJ8c8wXzB","executionInfo":{"status":"ok","timestamp":1648113019530,"user_tz":-120,"elapsed":32,"user":{"displayName":"Assaf La","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUaXBQVi1i3pv_IG6dyzlsX7aSwxWMcT_iQuRs8no=s64","userId":"07226046456222457646"}},"outputId":"547d80da-ac3d-4913-8a87-2872b26bba08"},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","  for (rule of document.styleSheets[0].cssRules){\n","    if (rule.selectorText=='body') {\n","      rule.style.fontSize = '12px'\n","      break\n","    }\n","  }\n","  "]},"metadata":{}}]},{"cell_type":"code","execution_count":10,"metadata":{"cellView":"code","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":30,"status":"ok","timestamp":1648113019530,"user":{"displayName":"Assaf La","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUaXBQVi1i3pv_IG6dyzlsX7aSwxWMcT_iQuRs8no=s64","userId":"07226046456222457646"},"user_tz":-120},"id":"M0FWfwVdGNma","outputId":"07788852-2dc6-44c7-c415-5497821aed73"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","  for (rule of document.styleSheets[0].cssRules){\n","    if (rule.selectorText=='body') {\n","      rule.style.fontSize = '12px'\n","      break\n","    }\n","  }\n","  "]},"metadata":{}}],"source":["#@title Train\n","def train(args, model, train_loader, optimizer, active_exit):\n","    \"\"\"train the model.\n","\n","    Arguments are\n","    * args:         command line arguments entered by user.\n","    * model:        convolutional neural network model.\n","    * train_loader: train data loader.\n","    * optimizer:    optimize the model during training.\n","    * epoch:        epoch number.\n","\n","    This trains the model and prints the results of each epochs.\n","    \"\"\"\n","    losses = []\n","    cost = []\n","    pred_losses = []\n","    cost_losses = []\n","    model.train()\n","    \n","    #disable batch normalization statistics on active exit during training\n","    model.apply(set_bn_eval)\n","    for name, layer in model.exits[active_exit].layers[0].named_modules():\n","        if isinstance(layer, torch.nn.BatchNorm2d):\n","            #ipdb.set_trace(context=6)\n","            layer.train()\n","    \n","    #ipdb.set_trace(context=6)\n","    for i in range(args.num_ee+1):\n","        cost.append(model.complexity[i][0]/model.complexity[-1][0])                \n","    \n","    # actual training starts\n","    #for batch_id, ((data, noise), target) in enumerate(train_loader):\n","    for batch_id, (data, target) in enumerate(train_loader):\n","        # fetch the current batch data\n","        data, target = data.to(args.device), target.to(args.device, dtype=torch.int64)\n","        exit_tag = None\n","        optimizer.zero_grad()\n","        cum_loss = 0\n","        #cost = []\n","\n","        # training settings for EENet based models\n","        if isinstance(model, (CustomEENet, EENet)):\n","            pred, conf = model(data)\n","            #ipdb.set_trace(context=6)\n","            #cost.append(1)#torch.tensor(1.0).to(args.device))\n","            \n","            if args.use_main_targets:\n","                _, target = torch.max(pred[args.num_ee], 1)\n","\n","            #cum_loss, pred_loss, cost_loss = loss_functions.loss(args, exit_tag, pred, target, conf, cost)\n","            \n","            cum_pred = 0\n","            cum_cost = 0\n","            cum_loss = 0\n","            pred_loss = 0\n","            cost_loss = 0\n","            cum_pred = conf[active_exit] * pred[active_exit] + (1-conf[active_exit]) * pred[args.num_ee]\n","            cum_cost = conf[active_exit] * cost[active_exit] + (1-conf[active_exit]) * 1\n","            pred_loss = F.nll_loss(cum_pred.log(), target)\n","            cum_loss = pred_loss + args.lambda_coef*cum_cost.mean()\n","            \n","            #ipdb.set_trace(context=8)\n","            \"\"\"\n","            cum_pred = [None] * args.num_ee + [pred[args.num_ee]]\n","            cum_cost = [None] * args.num_ee + [cost[args.num_ee]]\n","            cum_loss = 0\n","            pred_loss = 0\n","            cost_loss = 0\n","            for i in range(args.num_ee-1, active_exit-1, -1):\n","                cum_pred[i] = conf[i] * pred[i] + (1-conf[i]) * cum_pred[i+1]\n","                cum_cost[i] = conf[i] * cost[i] + (1-conf[i]) * cum_cost[i+1]\n","                #if i == active_exit:\n","                pred_loss = F.nll_loss(cum_pred[i].log(), target)\n","                cum_loss += pred_loss + args.lambda_coef*cum_cost[i].mean()\n","            cum_loss = cum_loss/(args.num_ee-1 - active_exit)\n","            \"\"\"\n","                    \n","        # training settings for other models\n","        else:\n","            pred = model(data)\n","            cum_loss = F.cross_entropy(pred, target)\n","\n","        #ipdb.set_trace(context=6)\n","        losses.append(float(cum_loss))\n","        pred_losses.append(float(pred_loss))\n","        cost_losses.append(float(cost_loss))\n","        cum_loss.backward()\n","        optimizer.step()\n","        \"\"\"\n","        for obj in gc.get_objects():\n","            try:\n","                if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):\n","                    print(type(obj), obj.size())\n","            except:\n","                pass\n","        \"\"\"\n","        #print(model.exits[1].classifier[0].weight)\n","    \n","    # print the training results of epoch\n","    result = {'train_loss': round(np.mean(losses), 4),\n","              'train_loss_sem': round(stats.sem(losses), 2),\n","              'pred_loss': round(np.mean(pred_losses), 4),\n","              'pred_loss_sem': round(stats.sem(pred_losses), 2),\n","              'cost_loss': round(np.mean(cost_losses), 4),\n","              'cost_loss_sem': round(stats.sem(cost_losses), 2)}\n","\n","    print('Train avg loss: {:.4f}'.format(result['train_loss']))\n","    \n","    return result"]},{"cell_type":"code","execution_count":11,"metadata":{"cellView":"code","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":29,"status":"ok","timestamp":1648113019531,"user":{"displayName":"Assaf La","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUaXBQVi1i3pv_IG6dyzlsX7aSwxWMcT_iQuRs8no=s64","userId":"07226046456222457646"},"user_tz":-120},"id":"_RxrxOmgGRto","outputId":"8214065a-2e93-460a-eb2f-e83b572cf0dc"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","  for (rule of document.styleSheets[0].cssRules){\n","    if (rule.selectorText=='body') {\n","      rule.style.fontSize = '12px'\n","      break\n","    }\n","  }\n","  "]},"metadata":{}}],"source":["#@title Validate\n","\n","def accuracy(output, target, topk=(1,)):\n","    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n","    maxk = max(topk)\n","    batch_size = target.size(0)\n","\n","    _, pred = output.topk(maxk, 1, True, True)\n","    pred = pred.t()\n","    correct = pred.eq(target.view(1, -1).expand_as(pred))\n","    \n","    res = []\n","    for k in topk:\n","        correct_k = correct[:k].view(-1).float().sum(0)\n","        res.append(correct_k.mul_(100.0 / batch_size))\n","    return res\n","\n","def validate(args, model, val_loader, active_exit, thresholds):\n","    batch = {'time':[], 'cost':[], 'flop':[], 'acc':[], 'val_loss':[]}\n","    exit_points = [0]*(args.num_ee+1)\n","    # switch to evaluate mode\n","    model.eval()\n","    main_ee_losses = []\n","        \n","    with torch.no_grad():\n","        starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n","        elapsed_time = 0\n","        \n","        for batch_id, (data, target) in enumerate(val_loader):\n","            batch_size = target.shape[0]        \n","            data, target = data.to(args.device), target.to(args.device, dtype=torch.int64)\n","            # compute output\n","            #start = time.process_time()\n","            elapsed_time = 0\n","            # results of EENet based models\n","            \n","            #if isinstance(model, (EENet, CustomEENet)):   \n","\n","            starter.record()\n","            preds, confs = model(data)\n","            ender.record()\n","            torch.cuda.synchronize()\n","            elapsed_time = starter.elapsed_time(ender)/batch_size                        \n","\n","            if mode == Mode.train_main:\n","                pred = preds[args.num_ee]\n","                cost = 1\n","                exit_points[args.num_ee] += batch_size\n","                flop = model.complexity[-1][0]\n","                pred_loss = F.nll_loss(pred.log(), target)\n","                main_ee_losses.append(float(pred_loss))\n","                \n","            elif mode == Mode.train_ee:\n","                losses = []\n","                costs = []\n","                flops = []\n","\n","                entropies = torch.empty((args.num_ee + 1, batch_size), dtype=torch.float)\n","                pred_losses = torch.empty((args.num_ee + 1, batch_size), dtype=torch.float)\n","                pred = torch.zeros((batch_size, preds[0].shape[1]), dtype=torch.float, device = 'cuda')\n","\n","                _, target_main = torch.max(preds[args.num_ee], 1)                \n","        \n","                if args.use_main_targets:\n","                    target = target_main\n","                \n","                for i in range(args.num_ee+1):\n","                    cost = model.complexity[i][0]/model.complexity[-1][0]\n","                    pred_losses[i] = F.nll_loss(preds[i].log(), target, reduction='none')\n","                    #ipdb.set_trace(context=3)\n","                    entropies[i] = torch.sum(preds[i] * preds[i].log(), 1)\n","                \n","                main_ee_loss = F.nll_loss(preds[args.num_ee].log(), target)\n","                main_ee_losses.append(float(main_ee_loss))\n","                \n","                for j in range(batch_size):\n","                    best_exit = args.num_ee\n","                    #for i in range(active_exit, args.num_ee):\n","                    for i in range(0, active_exit + 1):\n","                        if args.termination == 'entropy':   \n","                            if entropies[i][j] < args.loss_threshold:\n","                                best_exit = i\n","                                #ipdb.set_trace(context=6)\n","                                break\n","                        elif args.termination == 'confidence':   \n","                            if confs[i][j] > thresholds[active_exit]:\n","                                best_exit = i\n","                                break\n","                    \n","                    #ipdb.set_trace(context=3)\n","                    exit_points[best_exit] += 1\n","                    best_pred_loss = pred_losses[best_exit][j] #pred_losses[active_exit][j]\n","                    losses.append(float(best_pred_loss))\n","                    cost = model.complexity[best_exit][0]/model.complexity[-1][0] \n","                    flop = model.complexity[best_exit][0]\n","                    flops.append(float(flop))\n","                    costs.append(float(cost))\n","                    pred[j] = preds[best_exit][j]\n","                \n","                #ipdb.set_trace(context=3)\n","                cost = round(np.mean(costs), 4)\n","                pred_loss = round(np.mean(losses), 4)\n","                flop = round(np.mean(flops), 4)\n","                #ipdb.set_trace(context=3)                    \n","                losses = None\n","                costs = None\n","                flops = None\n","                                \n","            else:\n","                print('Unknown mode')\n","                \n","            #elapsed_time = time.process_time() - start\n","            #ipdb.set_trace(context=6)\n","            prec1 = accuracy(pred.float().data, target)[0]\n","            pred = None\n","                \n","            batch['acc'].append(float(prec1))\n","            batch['time'].append(elapsed_time)\n","            batch['cost'].append(cost*100.)\n","            batch['flop'].append(flop)\n","            batch['val_loss'].append(float(pred_loss))\n","            \n","    #ipdb.set_trace(context=6)\n","    print('main ee avg loss: ', round(np.mean(main_ee_losses), 4))\n","    utils.print_validation(args, batch, exit_points)\n","    \n","    result = {}\n","    for key, value in batch.items():\n","        result[key] = round(np.mean(value), 4)\n","        result[key+'_sem'] = round(stats.sem(value), 2)\n","    \n","    result['exit_points'] = exit_points\n","    result['exit_points_std'] = round(np.diff(exit_points).std(), 4)\n","    result['exit_points_std_sem'] = 0\n","    #result['exit_points_std'] = np.diff(exit_points).std()# / (np.max(exit_points) - np.min(exit_points))\n","    \n","    return result\n"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":29,"status":"ok","timestamp":1648113019532,"user":{"displayName":"Assaf La","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUaXBQVi1i3pv_IG6dyzlsX7aSwxWMcT_iQuRs8no=s64","userId":"07226046456222457646"},"user_tz":-120},"id":"UTyGwEMtGWT4","outputId":"f8de4b27-cfe1-4728-bb34-f5555ec0cd5e","cellView":"form"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","  for (rule of document.styleSheets[0].cssRules){\n","    if (rule.selectorText=='body') {\n","      rule.style.fontSize = '12px'\n","      break\n","    }\n","  }\n","  "]},"metadata":{}}],"source":["#@title run()\n","\n","def run_back(model, optimizer, lr_scheduler, args, train_loader, test_loader, writer):\n","    # best = {}\n","    # best_epoch = 0\n","\n","    writer_epoch = 0\n","    \n","    print('Running for {:5d} epochs'.format(args.epochs))\n","    try:\n","\n","        for active_exit in range(args.num_ee-1, -1, -1):\n","            disable_all_grads(model, args)\n","            #model.stages[active_exit].requires_grad_(False)\n","            for param in model.exits[active_exit].parameters():\n","                #ipdb.set_trace(context=3)\n","                param.requires_grad = True\n","            if active_exit < args.num_ee-1:\n","                for param in model.exits[active_exit + 1].parameters():\n","                    #ipdb.set_trace(context=3)\n","                    param.grad = None\n","            print('Enabled EE branche ', active_exit)\n","            print('loss threshold: ', thresholds[active_exit])\n","            #print_require_grads_only(model)\n","            #if not args.no_tensorboard:\n","            #    writer = SummaryWriter('../runs/train_eenet_experiment_1')\n","            torch.cuda.empty_cache()\n","            early_stopping = early_stop(patience=5)\n","        \n","            for epoch in range(args.start_epoch, args.epochs + 1):\n","                print('{:3d}:'.format(epoch), end='')\n","\n","                # two-stage training uses the loss version-1 after training for 25 epochs\n","                if args.two_stage and epoch > 25:\n","                    args.loss_func = \"v1\"\n","                \n","                result = {'epoch':epoch}\n","                \n","                result.update(train(args, model, train_loader, optimizer, active_exit))\n","                if not args.no_tensorboard:\n","                    writer_epoch += 1\n","                    writer.add_scalar(\"Train/loss\", result['train_loss'], writer_epoch)\n","                    for name, weight in model.named_parameters():\n","                        #ipdb.set_trace(context=3)\n","                        if 'exit' in name:\n","                            writer.add_histogram(name,weight, writer_epoch)\n","                        #writer.add_histogram(f'{name}.grad',weight.grad, epoch)\n","                \n","\n","                # use adaptive learning rate\n","                if args.adaptive_lr:\n","                    #lr_scheduler.step()\n","                    lr_scheduler(args, optimizer, epoch)\n","\n","                # validate and keep history at each log interval\n","                if epoch % args.log_interval == 0:\n","                    result.update(validate(args, model, test_loader, active_exit))\n","                    utils.save_history(args, result)\n","                    if not args.no_tensorboard:\n","                        writer.add_scalar(\"Val/loss\", result['val_loss'], writer_epoch)\n","                        writer.add_scalars('Val/acc_cost', {\n","                            'acc': result['acc'],\n","                            'cost': result['cost']\n","                        }, writer_epoch)\n","                        writer.add_scalar(\"Val/exit_points_std\", result['exit_points_std'], writer_epoch)\n","                        #writer.add_histogram('exit_points',np.array(result['exit_points']), epoch)\n","                    if args.early_stopping:\n","                        early_stopping(result['val_loss'])\n","                        if early_stopping.early_stop:\n","                            break\n","                    \n","                if not args.no_tensorboard:    \n","                    writer.flush()\n","                # save model parameters\n","                if not args.no_save_model:\n","                    utils.save_model(args, model, epoch)\n","    except KeyboardInterrupt:\n","        utils.close_history(args)\n","        utils.plot_history(args)\n","        if not args.no_tensorboard:\n","            writer.close()\n","        sys.exit()\n","    # print the best validation result\n","    \n","    best_epoch = utils.close_history(args)\n","\n","    # save the model giving the best validation results as a final model\n","    if args.save_best:\n","        utils.save_model(args, model, best_epoch, True)\n","    utils.plot_history(args)\n","    if not args.no_tensorboard:\n","        writer.close()\n"]},{"cell_type":"code","source":["#@title run()\n","\n","def run_fw(model, optimizer, lr_scheduler, args, train_loader, test_loader, writer):\n","    # best = {}\n","    # best_epoch = 0\n","\n","    writer_epoch = 0\n","    thresholds = [0.9, 0.9, 0.9, 0.9, 0.9, 0.8, 0.7, 0.6, 0.6, 0.6]\n","    \n","    print('Running for {:5d} epochs'.format(args.epochs))\n","    try:\n","\n","        for active_exit in range(0, args.num_ee):\n","            disable_all_grads(model, args)\n","            #model.stages[active_exit].requires_grad_(False)\n","            for param in model.exits[active_exit].parameters():\n","                #ipdb.set_trace(context=3)\n","                param.requires_grad = True\n","            if active_exit > 0:\n","                for param in model.exits[active_exit - 1].parameters():\n","                    #ipdb.set_trace(context=3)\n","                    param.grad = None\n","            print('Enabled EE branche ', active_exit)\n","            print('loss threshold: ', thresholds[active_exit])\n","            #print_require_grads_only(model)\n","            #if not args.no_tensorboard:\n","            #    writer = SummaryWriter('../runs/train_eenet_experiment_1')\n","            torch.cuda.empty_cache()\n","            early_stopping = early_stop(patience=5)\n","        \n","            for epoch in range(args.start_epoch, args.epochs + 1):\n","                print('{:3d}:'.format(epoch), end='')\n","\n","                # two-stage training uses the loss version-1 after training for 25 epochs\n","                if args.two_stage and epoch > 25:\n","                    args.loss_func = \"v1\"\n","                \n","                result = {'epoch':epoch}\n","                \n","                result.update(train(args, model, train_loader, optimizer, active_exit))\n","                if not args.no_tensorboard:\n","                    writer_epoch += 1\n","                    writer.add_scalar(\"Train/loss\", result['train_loss'], writer_epoch)\n","                    for name, weight in model.named_parameters():\n","                        #ipdb.set_trace(context=3)\n","                        if 'exit' in name:\n","                            writer.add_histogram(name,weight, writer_epoch)\n","                        #writer.add_histogram(f'{name}.grad',weight.grad, epoch)\n","                \n","\n","                # use adaptive learning rate\n","                if args.adaptive_lr:\n","                    #lr_scheduler.step()\n","                    lr_scheduler(args, optimizer, epoch)\n","\n","                # validate and keep history at each log interval\n","                if epoch % args.log_interval == 0:\n","                    result.update(validate(args, model, test_loader, active_exit, thresholds))\n","                    utils.save_history(args, result)\n","                    if not args.no_tensorboard:\n","                        writer.add_scalar(\"Val/loss\", result['val_loss'], writer_epoch)\n","                        writer.add_scalars('Val/acc_cost', {\n","                            'acc': result['acc'],\n","                            'cost': result['cost']\n","                        }, writer_epoch)\n","                        writer.add_scalar(\"Val/exit_points_std\", result['exit_points_std'], writer_epoch)\n","                        #writer.add_histogram('exit_points',np.array(result['exit_points']), epoch)\n","                    if args.early_stopping:\n","                        early_stopping(result['val_loss'])\n","                        if early_stopping.early_stop:\n","                            break\n","                    \n","                if not args.no_tensorboard:    \n","                    writer.flush()\n","                # save model parameters\n","                if not args.no_save_model:\n","                    utils.save_model(args, model, epoch)\n","    except KeyboardInterrupt:\n","        utils.close_history(args)\n","        utils.plot_history(args)\n","        if not args.no_tensorboard:\n","            writer.close()\n","        sys.exit()\n","    # print the best validation result\n","    \n","    best_epoch = utils.close_history(args)\n","\n","    # save the model giving the best validation results as a final model\n","    if args.save_best:\n","        utils.save_model(args, model, best_epoch, True)\n","    utils.plot_history(args)\n","    if not args.no_tensorboard:\n","        writer.close()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"cellView":"code","id":"pNn7YqKlkYm5","executionInfo":{"status":"ok","timestamp":1648113019532,"user_tz":-120,"elapsed":28,"user":{"displayName":"Assaf La","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUaXBQVi1i3pv_IG6dyzlsX7aSwxWMcT_iQuRs8no=s64","userId":"07226046456222457646"}},"outputId":"c628a1bc-95ee-4e9f-ca19-50c06538833e"},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","  for (rule of document.styleSheets[0].cssRules){\n","    if (rule.selectorText=='body') {\n","      rule.style.fontSize = '12px'\n","      break\n","    }\n","  }\n","  "]},"metadata":{}}]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":26,"status":"ok","timestamp":1648113019532,"user":{"displayName":"Assaf La","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUaXBQVi1i3pv_IG6dyzlsX7aSwxWMcT_iQuRs8no=s64","userId":"07226046456222457646"},"user_tz":-120},"id":"6cWNwDHcGa8Y","outputId":"e6d07bd6-f39f-46d4-ea41-2a60a8d0df77"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","  for (rule of document.styleSheets[0].cssRules){\n","    if (rule.selectorText=='body') {\n","      rule.style.fontSize = '12px'\n","      break\n","    }\n","  }\n","  "]},"metadata":{}}],"source":["#@title enable_branches_training_only\n","def set_bn_eval(m):\n","    classname = m.__class__.__name__\n","    if classname.find('BatchNorm2d') != -1:\n","        m.eval()\n","    \n","def disable_all_grads(model, args):\n","    if args.model == 'eenet8':\n","        model.set_ee_disable(False)\n","        model.initblock.requires_grad_(False)\n","        model.basicblock1.requires_grad_(False)\n","        model.basicblock2.requires_grad_(False)\n","        model.basicblock3.requires_grad_(False)\n","        model.finalblock.requires_grad_(False)\n","        model.classifier.requires_grad_(False)\n","        model.conv2d_6.requires_grad_(False)\n","        model.conv2d_9.requires_grad_(False)\n","    else:\n","        model.set_ee_disable(False)\n","        for idx, exitblock in enumerate(model.exits):\n","            model.stages[idx].requires_grad_(False)\n","            for param in model.exits.parameters():\n","                #ipdb.set_trace(context=3)\n","                param.requires_grad = False\n","            #model.exits.requires_grad(True)\n","\n","        model.stages[-1].requires_grad_(False)\n","        model.classifier.requires_grad_(False)\n","        model.confidence.requires_grad_(False)\n","\n","        #model.apply(set_bn_eval)\n","        \n","        #params = model_post.state_dict()\n","        #print(params)                "]},{"cell_type":"code","execution_count":15,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1648113019532,"user":{"displayName":"Assaf La","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUaXBQVi1i3pv_IG6dyzlsX7aSwxWMcT_iQuRs8no=s64","userId":"07226046456222457646"},"user_tz":-120},"id":"9SaYNXpxXzhT","outputId":"70d14931-1086-40f4-9db5-c773735152c5"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","  for (rule of document.styleSheets[0].cssRules){\n","    if (rule.selectorText=='body') {\n","      rule.style.fontSize = '12px'\n","      break\n","    }\n","  }\n","  "]},"metadata":{}}],"source":["#@title load data\n","from torch.utils.data import Dataset, TensorDataset, DataLoader\n","\n","class CustomTensorDataset(Dataset):\n","    \"\"\"TensorDataset with support of transforms.\n","    \"\"\"\n","    def __init__(self, tensors, transform=None):\n","        #ipdb.set_trace(context=6)\n","        assert all(tensors[0].size(0) == tensor.size(0) for tensor in tensors)\n","        self.tensors = tensors\n","        self.transform = transform\n","\n","    def __getitem__(self, index):\n","        x = self.tensors[0][index]\n","\n","        if self.transform:\n","            x = self.transform(x)\n","\n","        y = self.tensors[1][index]\n","        \n","        return x, y\n","\n","    def __len__(self):\n","        return self.tensors[0].size(0)\n","        \n","def load_data(args):\n","    return utils.load_dataset(args)#load_custom_dataset(args)\n","\n","def load_data_serialized(args):\n","    serialized_data_dir = 'serialized_data'\n","    \n","    data_file_train = serialized_data_dir + '/datas_train' + '.pt'\n","    data_train = torch.load(data_file_train)\n","    print('loaded data train at: ', data_file_train)\n","    \n","    data_file_test = serialized_data_dir + '/datas_test' + '.pt'\n","    data_test = torch.load(data_file_test)\n","    print('loaded data test at: ', data_file_test)\n","    \n","    gt_file_train = serialized_data_dir + '/targets_train' + '.pt'\n","    target_train = torch.load(gt_file_train)\n","    print('loaded exits ground truths train at: ', gt_file_train)\n","    \n","    gt_file_test = serialized_data_dir + '/targets_test' + '.pt'\n","    target_test = torch.load(gt_file_test)\n","    print('loaded exits ground truths test at: ', gt_file_test)\n","\n","    data_train, data_test, target_train, target_test = train_test_split(data_train,\\\n","                                                                        target_train, test_size=0.2, shuffle=False)\n","    \n","    data_train, target_train = torch.from_numpy(data_train), torch.from_numpy(target_train)    \n","    data_test, target_test = torch.from_numpy(data_test), torch.from_numpy(target_test)\n","    \n","    train_set = CustomTensorDataset(tensors=(data_train, target_train))    \n","    validation_set = CustomTensorDataset(tensors=(data_test, target_test))\n","    loader_train = torch.utils.data.DataLoader(train_set, batch_size=args.batch_size, shuffle=args.shuffle_train)\n","    loader_val = torch.utils.data.DataLoader(validation_set, batch_size=args.test_batch, shuffle=args.shuffle_test)\n","\n","    return loader_train, loader_val"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1648113019533,"user":{"displayName":"Assaf La","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUaXBQVi1i3pv_IG6dyzlsX7aSwxWMcT_iQuRs8no=s64","userId":"07226046456222457646"},"user_tz":-120},"id":"TiAPblzAGeLz","outputId":"e566a010-bebf-4a5a-a5ff-7c81ff3caffe"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","  for (rule of document.styleSheets[0].cssRules){\n","    if (rule.selectorText=='body') {\n","      rule.style.fontSize = '12px'\n","      break\n","    }\n","  }\n","  "]},"metadata":{}}],"source":["#@title main\n","\n","\"\"\"Main function of the program.\n","\n","The function loads the dataset and calls training and validation functions.\n","\"\"\"\n","%load_ext autoreload\n","%autoreload 2\n","\n","import importlib\n","importlib.reload(config)\n","importlib.reload(loss_functions)\n","importlib.reload(utils)\n","#from eenet import EENet\n","#from gatednet import GatedNet, GatedNetS\n","from enum import Enum\n","\n","class Mode(Enum):\n","    train_main = 0\n","    train_ee = 1\n","    generate_exits_gt = 2 \n","    train_gating = 3\n","    generate_relative_loss = 4 \n","    plot_relative_loss = 5\n","    calc_relative_time = 6\n","\n","def main(mode: Mode, writer):\n","    print(mode.value)\n","    args = config.args_global\n","    args += config.argu[mode.value]\n","    \n","    %pwd\n","    model, optimizer, lr_scheduler, args = initializer(args)\n","    print(args)\n","    \n","    train_loader, test_loader = load_data(args)\n","    #train_loader, test_loader = load_data_serialized(args)\n","    run_fw(model, optimizer, lr_scheduler, args, train_loader, test_loader, writer)\n","    \n","    print('Finished')"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"v9gjbi-OCQ2J","outputId":"c21be83b-1410-45eb-84c9-2ad3f873e384","executionInfo":{"status":"error","timestamp":1648114892171,"user_tz":-120,"elapsed":1872662,"user":{"displayName":"Assaf La","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUaXBQVi1i3pv_IG6dyzlsX7aSwxWMcT_iQuRs8no=s64","userId":"07226046456222457646"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","  for (rule of document.styleSheets[0].cssRules){\n","    if (rule.selectorText=='body') {\n","      rule.style.fontSize = '12px'\n","      break\n","    }\n","  }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["ERROR: Timed out waiting for TensorBoard to start. It may still be running as pid 1356."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","  for (rule of document.styleSheets[0].cssRules){\n","    if (rule.selectorText=='body') {\n","      rule.style.fontSize = '12px'\n","      break\n","    }\n","  }\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["1\n","use cuda:  True  device:  cuda\n","empty model loaded at:  main_models/models/cifar10/eenet110/after_main_training/ee10/conv2/model.pt\n","ee-block-0: flops=19.78 MMac, params=19.34 k, cost-rate=0.08\n","ee-block-1: flops=34.23 MMac, params=33.35 k, cost-rate=0.13\n","ee-block-2: flops=43.86 MMac, params=42.7 k, cost-rate=0.17\n","ee-block-3: flops=53.49 MMac, params=52.04 k, cost-rate=0.21\n","ee-block-4: flops=63.13 MMac, params=61.39 k, cost-rate=0.25\n","ee-block-5: flops=72.76 MMac, params=70.73 k, cost-rate=0.28\n","ee-block-6: flops=82.4 MMac, params=80.08 k, cost-rate=0.32\n","ee-block-7: flops=92.03 MMac, params=89.42 k, cost-rate=0.36\n","ee-block-8: flops=100.48 MMac, params=136.57 k, cost-rate=0.39\n","ee-block-9: flops=110.01 MMac, params=173.69 k, cost-rate=0.43\n","exit-block: flops=256.32 MMac, params=1.73 M, cost-rate=1.00\n","Namespace(adaptive_lr=False, add_noise=False, batch_size=128, clear_dirs=True, dataset='cifar10', device=device(type='cuda'), distribution='fine', early_stopping=True, ee_costs=None, epochs=30, exit_type='conv2', filters=4, gated_models_dir='gated_models/cifar10/no_noise', ground_truths_dir='gated_ground_truths/cifar10', hist_file=<_io.TextIOWrapper name='runs/results/cifar10/eenet110/ee10_fine_conv2_lambda_1.7/history.csv' mode='a' encoding='UTF-8'>, input_shape=(3, 32, 32), lambda_coef=1.7, load_model='main_models/models/cifar10/eenet110/after_main_training/ee10/conv2/model.pt', log_interval=1, loss_func='v7', loss_main=0, loss_threshold=0.8, lr=0.0005, max_depth=6, max_noise_snr=30, min_noise_snr=-5, model='eenet110', models_dir='runs/models/cifar10/eenet110/ee10_fine_conv2_lambda_1.7', momentum=0.9, multi_gpu=False, no_cuda=False, no_save_model=False, no_tensorboard=False, noise_snr=0, noise_str='no_noise', num_classes=10, num_ee=10, num_noise_levels=5, optimizer='Adam', plot_history=False, recorder=<_csv.writer object at 0x7f4059d73770>, relative_losses_dir='relative_losses/cifar10/no_noise', results_dir='runs/results/cifar10/eenet110/ee10_fine_conv2_lambda_1.7', save_best=False, seed=1, shuffle_test=False, shuffle_train=True, start_epoch=1, termination='confidence', test_batch=128, two_stage=False, use_main_targets=True, validate=True, weight_decay=0.0001)\n","Files already downloaded and verified\n","Files already downloaded and verified\n","Running for    30 epochs\n","Enabled EE branche  0\n","loss threshold:  0.9\n","  1:Train avg loss: 1.5470\n","main ee avg loss:  0.0967\n","     Test avg time: 0.2418msec; avg val_loss: 0.1021; avg val_acc: 99.64%\n","\tavg val_cost: 99.34%; exits: <72,0,0,0,0,0,0,0,0,0,9928,>\n","saving model:  runs/models/cifar10/eenet110/ee10_fine_conv2_lambda_1.7/model.v1.pt\n","  2:Train avg loss: 1.4763\n","main ee avg loss:  0.0967\n","     Test avg time: 0.2413msec; avg val_loss: 0.1202; avg val_acc: 99.17%\n","\tavg val_cost: 97.56%; exits: <261,0,0,0,0,0,0,0,0,0,9739,>\n","INFO: Early stopping counter 1 of 5\n","saving model:  runs/models/cifar10/eenet110/ee10_fine_conv2_lambda_1.7/model.v2.pt\n","  3:Train avg loss: 1.4229\n","main ee avg loss:  0.0967\n","     Test avg time: 0.2407msec; avg val_loss: 0.1303; avg val_acc: 98.76%\n","\tavg val_cost: 95.60%; exits: <482,0,0,0,0,0,0,0,0,0,9518,>\n","INFO: Early stopping counter 2 of 5\n","saving model:  runs/models/cifar10/eenet110/ee10_fine_conv2_lambda_1.7/model.v3.pt\n","  4:Train avg loss: 1.3840\n","main ee avg loss:  0.0967\n","     Test avg time: 0.2410msec; avg val_loss: 0.1302; avg val_acc: 98.64%\n","\tavg val_cost: 95.02%; exits: <539,0,0,0,0,0,0,0,0,0,9461,>\n","INFO: Early stopping counter 3 of 5\n","saving model:  runs/models/cifar10/eenet110/ee10_fine_conv2_lambda_1.7/model.v4.pt\n","  5:Train avg loss: 1.3537\n","main ee avg loss:  0.0967\n","     Test avg time: 0.2408msec; avg val_loss: 0.1501; avg val_acc: 98.10%\n","\tavg val_cost: 94.04%; exits: <639,0,0,0,0,0,0,0,0,0,9361,>\n","INFO: Early stopping counter 4 of 5\n","saving model:  runs/models/cifar10/eenet110/ee10_fine_conv2_lambda_1.7/model.v5.pt\n","  6:Train avg loss: 1.3269\n","main ee avg loss:  0.0967\n","     Test avg time: 0.2408msec; avg val_loss: 0.1436; avg val_acc: 98.35%\n","\tavg val_cost: 93.71%; exits: <682,0,0,0,0,0,0,0,0,0,9318,>\n","INFO: Early stopping counter 5 of 5\n","INFO: Early stopping\n","Enabled EE branche  1\n","loss threshold:  0.9\n","  1:Train avg loss: 1.6007\n","main ee avg loss:  0.0967\n","     Test avg time: 0.2415msec; avg val_loss: 0.1437; avg val_acc: 98.35%\n","\tavg val_cost: 93.66%; exits: <682,6,0,0,0,0,0,0,0,0,9312,>\n","saving model:  runs/models/cifar10/eenet110/ee10_fine_conv2_lambda_1.7/model.v1.pt\n","  2:Train avg loss: 1.5238\n","main ee avg loss:  0.0967\n","     Test avg time: 0.2411msec; avg val_loss: 0.1442; avg val_acc: 98.34%\n","\tavg val_cost: 93.60%; exits: <682,13,0,0,0,0,0,0,0,0,9305,>\n","INFO: Early stopping counter 1 of 5\n","saving model:  runs/models/cifar10/eenet110/ee10_fine_conv2_lambda_1.7/model.v2.pt\n","  3:Train avg loss: 1.4702\n","main ee avg loss:  0.0967\n","     Test avg time: 0.2408msec; avg val_loss: 0.1502; avg val_acc: 98.10%\n","\tavg val_cost: 93.09%; exits: <682,66,0,0,0,0,0,0,0,0,9252,>\n","INFO: Early stopping counter 2 of 5\n","saving model:  runs/models/cifar10/eenet110/ee10_fine_conv2_lambda_1.7/model.v3.pt\n","  4:Train avg loss: 1.4288\n","main ee avg loss:  0.0967\n","     Test avg time: 0.2409msec; avg val_loss: 0.1572; avg val_acc: 97.85%\n","\tavg val_cost: 92.74%; exits: <682,107,0,0,0,0,0,0,0,0,9211,>\n","INFO: Early stopping counter 3 of 5\n","saving model:  runs/models/cifar10/eenet110/ee10_fine_conv2_lambda_1.7/model.v4.pt\n","  5:Train avg loss: 1.3956\n","main ee avg loss:  0.0967\n","     Test avg time: 0.2426msec; avg val_loss: 0.1492; avg val_acc: 98.19%\n","\tavg val_cost: 93.38%; exits: <682,39,0,0,0,0,0,0,0,0,9279,>\n","INFO: Early stopping counter 4 of 5\n","saving model:  runs/models/cifar10/eenet110/ee10_fine_conv2_lambda_1.7/model.v5.pt\n","  6:Train avg loss: 1.3692\n","main ee avg loss:  0.0967\n","     Test avg time: 0.2407msec; avg val_loss: 0.1507; avg val_acc: 98.11%\n","\tavg val_cost: 93.21%; exits: <682,59,0,0,0,0,0,0,0,0,9259,>\n","INFO: Early stopping counter 5 of 5\n","INFO: Early stopping\n","Enabled EE branche  2\n","loss threshold:  0.9\n","  1:Train avg loss: 1.6339\n","main ee avg loss:  0.0967\n","     Test avg time: 0.2434msec; avg val_loss: 0.1507; avg val_acc: 98.11%\n","\tavg val_cost: 93.19%; exits: <682,59,2,0,0,0,0,0,0,0,9257,>\n","saving model:  runs/models/cifar10/eenet110/ee10_fine_conv2_lambda_1.7/model.v1.pt\n","  2:Train avg loss: 1.5705\n","main ee avg loss:  0.0967\n","     Test avg time: 0.2414msec; avg val_loss: 0.1518; avg val_acc: 98.08%\n","\tavg val_cost: 93.14%; exits: <682,59,8,0,0,0,0,0,0,0,9251,>\n","INFO: Early stopping counter 1 of 5\n","saving model:  runs/models/cifar10/eenet110/ee10_fine_conv2_lambda_1.7/model.v2.pt\n","  3:Train avg loss: 1.5163\n","main ee avg loss:  0.0967\n","     Test avg time: 0.2414msec; avg val_loss: 0.1507; avg val_acc: 98.11%\n","\tavg val_cost: 93.19%; exits: <682,59,2,0,0,0,0,0,0,0,9257,>\n","saving model:  runs/models/cifar10/eenet110/ee10_fine_conv2_lambda_1.7/model.v3.pt\n","  4:Train avg loss: 1.4766\n","main ee avg loss:  0.0967\n","     Test avg time: 0.2414msec; avg val_loss: 0.1520; avg val_acc: 98.09%\n","\tavg val_cost: 93.08%; exits: <682,59,15,0,0,0,0,0,0,0,9244,>\n","INFO: Early stopping counter 2 of 5\n","saving model:  runs/models/cifar10/eenet110/ee10_fine_conv2_lambda_1.7/model.v4.pt\n","  5:Train avg loss: 1.4423\n","main ee avg loss:  0.0967\n","     Test avg time: 0.2409msec; avg val_loss: 0.1519; avg val_acc: 98.09%\n","\tavg val_cost: 93.13%; exits: <682,59,9,0,0,0,0,0,0,0,9250,>\n","INFO: Early stopping counter 3 of 5\n","saving model:  runs/models/cifar10/eenet110/ee10_fine_conv2_lambda_1.7/model.v5.pt\n","  6:Train avg loss: 1.4079\n","main ee avg loss:  0.0967\n","     Test avg time: 0.2414msec; avg val_loss: 0.1536; avg val_acc: 98.04%\n","\tavg val_cost: 92.99%; exits: <682,59,27,0,0,0,0,0,0,0,9232,>\n","INFO: Early stopping counter 4 of 5\n","saving model:  runs/models/cifar10/eenet110/ee10_fine_conv2_lambda_1.7/model.v6.pt\n","  7:Train avg loss: 1.3762\n","main ee avg loss:  0.0967\n","     Test avg time: 0.2414msec; avg val_loss: 0.1527; avg val_acc: 98.06%\n","\tavg val_cost: 93.02%; exits: <682,59,23,0,0,0,0,0,0,0,9236,>\n","INFO: Early stopping counter 5 of 5\n","INFO: Early stopping\n","Enabled EE branche  3\n","loss threshold:  0.9\n","  1:Train avg loss: 1.6615\n","main ee avg loss:  0.0967\n","     Test avg time: 0.2414msec; avg val_loss: 0.1527; avg val_acc: 98.06%\n","\tavg val_cost: 93.02%; exits: <682,59,23,0,0,0,0,0,0,0,9236,>\n","saving model:  runs/models/cifar10/eenet110/ee10_fine_conv2_lambda_1.7/model.v1.pt\n","  2:Train avg loss: 1.5914\n","main ee avg loss:  0.0967\n","     Test avg time: 0.2408msec; avg val_loss: 0.1527; avg val_acc: 98.06%\n","\tavg val_cost: 92.99%; exits: <682,59,23,3,0,0,0,0,0,0,9233,>\n","saving model:  runs/models/cifar10/eenet110/ee10_fine_conv2_lambda_1.7/model.v2.pt\n","  3:Train avg loss: 1.5455\n","main ee avg loss:  0.0967\n","     Test avg time: 0.2409msec; avg val_loss: 0.1539; avg val_acc: 98.04%\n","\tavg val_cost: 92.85%; exits: <682,59,23,22,0,0,0,0,0,0,9214,>\n","INFO: Early stopping counter 1 of 5\n","saving model:  runs/models/cifar10/eenet110/ee10_fine_conv2_lambda_1.7/model.v3.pt\n","  4:Train avg loss: 1.5075\n","main ee avg loss:  0.0967\n","     Test avg time: 0.2412msec; avg val_loss: 0.1559; avg val_acc: 98.00%\n","\tavg val_cost: 92.66%; exits: <682,59,23,46,0,0,0,0,0,0,9190,>\n","INFO: Early stopping counter 2 of 5\n","saving model:  runs/models/cifar10/eenet110/ee10_fine_conv2_lambda_1.7/model.v4.pt\n","  5:Train avg loss: 1.4719\n","main ee avg loss:  0.0967\n","     Test avg time: 0.2412msec; avg val_loss: 0.1559; avg val_acc: 97.97%\n","\tavg val_cost: 92.59%; exits: <682,59,23,55,0,0,0,0,0,0,9181,>\n","INFO: Early stopping counter 3 of 5\n","saving model:  runs/models/cifar10/eenet110/ee10_fine_conv2_lambda_1.7/model.v5.pt\n","  6:Train avg loss: 1.4391\n","main ee avg loss:  0.0967\n","     Test avg time: 0.2432msec; avg val_loss: 0.1720; avg val_acc: 97.41%\n","\tavg val_cost: 91.51%; exits: <682,59,23,186,0,0,0,0,0,0,9050,>\n","INFO: Early stopping counter 4 of 5\n","saving model:  runs/models/cifar10/eenet110/ee10_fine_conv2_lambda_1.7/model.v6.pt\n","  7:Train avg loss: 1.4092\n","main ee avg loss:  0.0967\n","     Test avg time: 0.2410msec; avg val_loss: 0.1724; avg val_acc: 97.41%\n","\tavg val_cost: 91.50%; exits: <682,59,23,187,0,0,0,0,0,0,9049,>\n","INFO: Early stopping counter 5 of 5\n","INFO: Early stopping\n","Enabled EE branche  4\n","loss threshold:  0.9\n","  1:Train avg loss: 1.6973\n","main ee avg loss:  0.0967\n","     Test avg time: 0.2414msec; avg val_loss: 0.1724; avg val_acc: 97.41%\n","\tavg val_cost: 91.50%; exits: <682,59,23,187,0,0,0,0,0,0,9049,>\n","saving model:  runs/models/cifar10/eenet110/ee10_fine_conv2_lambda_1.7/model.v1.pt\n","  2:Train avg loss: 1.6405\n","main ee avg loss:  0.0967\n","     Test avg time: 0.2434msec; avg val_loss: 0.1724; avg val_acc: 97.41%\n","\tavg val_cost: 91.50%; exits: <682,59,23,187,0,0,0,0,0,0,9049,>\n","saving model:  runs/models/cifar10/eenet110/ee10_fine_conv2_lambda_1.7/model.v2.pt\n","  3:Train avg loss: 1.6056\n","main ee avg loss:  0.0967\n","     Test avg time: 0.2418msec; avg val_loss: 0.1724; avg val_acc: 97.41%\n","\tavg val_cost: 91.49%; exits: <682,59,23,187,1,0,0,0,0,0,9048,>\n","saving model:  runs/models/cifar10/eenet110/ee10_fine_conv2_lambda_1.7/model.v3.pt\n","  4:Train avg loss: 1.5718\n","main ee avg loss:  0.0967\n","     Test avg time: 0.2410msec; avg val_loss: 0.1742; avg val_acc: 97.36%\n","\tavg val_cost: 91.32%; exits: <682,59,23,187,24,0,0,0,0,0,9025,>\n","INFO: Early stopping counter 1 of 5\n","saving model:  runs/models/cifar10/eenet110/ee10_fine_conv2_lambda_1.7/model.v4.pt\n","  5:Train avg loss: 1.5380\n","main ee avg loss:  0.0967\n","     Test avg time: 0.2421msec; avg val_loss: 0.1753; avg val_acc: 97.33%\n","\tavg val_cost: 90.99%; exits: <682,59,23,187,68,0,0,0,0,0,8981,>\n","INFO: Early stopping counter 2 of 5\n","saving model:  runs/models/cifar10/eenet110/ee10_fine_conv2_lambda_1.7/model.v5.pt\n","  6:Train avg loss: 1.5113\n","main ee avg loss:  0.0967\n","     Test avg time: 0.2416msec; avg val_loss: 0.1770; avg val_acc: 97.31%\n","\tavg val_cost: 90.91%; exits: <682,59,23,187,79,0,0,0,0,0,8970,>\n","INFO: Early stopping counter 3 of 5\n","saving model:  runs/models/cifar10/eenet110/ee10_fine_conv2_lambda_1.7/model.v6.pt\n","  7:Train avg loss: 1.4835\n","main ee avg loss:  0.0967\n","     Test avg time: 0.2411msec; avg val_loss: 0.1907; avg val_acc: 96.90%\n","\tavg val_cost: 89.27%; exits: <682,59,23,187,299,0,0,0,0,0,8750,>\n","INFO: Early stopping counter 4 of 5\n","saving model:  runs/models/cifar10/eenet110/ee10_fine_conv2_lambda_1.7/model.v7.pt\n","  8:Train avg loss: 1.4581\n","main ee avg loss:  0.0967\n","     Test avg time: 0.2413msec; avg val_loss: 0.1822; avg val_acc: 97.12%\n","\tavg val_cost: 90.12%; exits: <682,59,23,187,185,0,0,0,0,0,8864,>\n","INFO: Early stopping counter 5 of 5\n","INFO: Early stopping\n","Enabled EE branche  5\n","loss threshold:  0.8\n","  1:Train avg loss: 1.7534\n","main ee avg loss:  0.0967\n","     Test avg time: 0.2421msec; avg val_loss: 0.7978; avg val_acc: 74.42%\n","\tavg val_cost: 50.62%; exits: <4533,155,414,298,77,0,0,0,0,0,4523,>\n","saving model:  runs/models/cifar10/eenet110/ee10_fine_conv2_lambda_1.7/model.v1.pt\n","  2:Train avg loss: 1.6878\n","main ee avg loss:  0.0967\n","     Test avg time: 0.2415msec; avg val_loss: 0.7978; avg val_acc: 74.42%\n","\tavg val_cost: 50.62%; exits: <4533,155,414,298,77,0,0,0,0,0,4523,>\n","saving model:  runs/models/cifar10/eenet110/ee10_fine_conv2_lambda_1.7/model.v2.pt\n","  3:Train avg loss: 1.6484\n","main ee avg loss:  0.0967\n","     Test avg time: 0.2412msec; avg val_loss: 0.7978; avg val_acc: 74.42%\n","\tavg val_cost: 50.62%; exits: <4533,155,414,298,77,0,0,0,0,0,4523,>\n","saving model:  runs/models/cifar10/eenet110/ee10_fine_conv2_lambda_1.7/model.v3.pt\n","  4:Train avg loss: 1.6162\n","main ee avg loss:  0.0967\n","     Test avg time: 0.2429msec; avg val_loss: 0.7980; avg val_acc: 74.41%\n","\tavg val_cost: 50.61%; exits: <4533,155,414,298,77,1,0,0,0,0,4522,>\n","INFO: Early stopping counter 1 of 5\n","saving model:  runs/models/cifar10/eenet110/ee10_fine_conv2_lambda_1.7/model.v4.pt\n","  5:Train avg loss: 1.5871\n","main ee avg loss:  0.0967\n","     Test avg time: 0.2423msec; avg val_loss: 0.7979; avg val_acc: 74.42%\n","\tavg val_cost: 50.61%; exits: <4533,155,414,298,77,1,0,0,0,0,4522,>\n","INFO: Early stopping counter 2 of 5\n","saving model:  runs/models/cifar10/eenet110/ee10_fine_conv2_lambda_1.7/model.v5.pt\n","  6:Train avg loss: 1.5607\n","main ee avg loss:  0.0967\n","     Test avg time: 0.2414msec; avg val_loss: 0.7989; avg val_acc: 74.39%\n","\tavg val_cost: 50.56%; exits: <4533,155,414,298,77,9,0,0,0,0,4514,>\n","INFO: Early stopping counter 3 of 5\n","saving model:  runs/models/cifar10/eenet110/ee10_fine_conv2_lambda_1.7/model.v6.pt\n","  7:Train avg loss: 1.5343\n","main ee avg loss:  0.0967\n","     Test avg time: 0.2417msec; avg val_loss: 0.8057; avg val_acc: 74.15%\n","\tavg val_cost: 50.25%; exits: <4533,155,414,298,77,52,0,0,0,0,4471,>\n","INFO: Early stopping counter 4 of 5\n","saving model:  runs/models/cifar10/eenet110/ee10_fine_conv2_lambda_1.7/model.v7.pt\n","  8:Train avg loss: 1.5093\n","main ee avg loss:  0.0967\n","     Test avg time: 0.2412msec; avg val_loss: 0.8026; avg val_acc: 74.22%\n","\tavg val_cost: 50.36%; exits: <4533,155,414,298,77,37,0,0,0,0,4486,>\n","INFO: Early stopping counter 5 of 5\n","INFO: Early stopping\n","Enabled EE branche  6\n","loss threshold:  0.7\n","  1:Train avg loss: 1.7432\n","main ee avg loss:  0.0967\n","     Test avg time: 0.2416msec; avg val_loss: 1.5097; avg val_acc: 47.06%\n","\tavg val_cost: 10.38%; exits: <9525,88,81,44,5,0,0,0,0,0,257,>\n","saving model:  runs/models/cifar10/eenet110/ee10_fine_conv2_lambda_1.7/model.v1.pt\n","  2:Train avg loss: 1.6926\n","main ee avg loss:  0.0967\n","     Test avg time: 0.2411msec; avg val_loss: 1.5097; avg val_acc: 47.06%\n","\tavg val_cost: 10.38%; exits: <9525,88,81,44,5,0,0,0,0,0,257,>\n","saving model:  runs/models/cifar10/eenet110/ee10_fine_conv2_lambda_1.7/model.v2.pt\n","  3:Train avg loss: 1.6659\n","main ee avg loss:  0.0967\n","     Test avg time: 0.2414msec; avg val_loss: 1.5097; avg val_acc: 47.06%\n","\tavg val_cost: 10.38%; exits: <9525,88,81,44,5,0,0,0,0,0,257,>\n","saving model:  runs/models/cifar10/eenet110/ee10_fine_conv2_lambda_1.7/model.v3.pt\n","  4:Train avg loss: 1.6263\n","main ee avg loss:  0.0967\n","     Test avg time: 0.2417msec; avg val_loss: 1.5097; avg val_acc: 47.06%\n","\tavg val_cost: 10.38%; exits: <9525,88,81,44,5,0,0,0,0,0,257,>\n","saving model:  runs/models/cifar10/eenet110/ee10_fine_conv2_lambda_1.7/model.v4.pt\n","  5:Train avg loss: 1.5879\n","main ee avg loss:  0.0967\n","     Test avg time: 0.2411msec; avg val_loss: 1.5097; avg val_acc: 47.06%\n","\tavg val_cost: 10.38%; exits: <9525,88,81,44,5,0,0,0,0,0,257,>\n","saving model:  runs/models/cifar10/eenet110/ee10_fine_conv2_lambda_1.7/model.v5.pt\n","  6:Train avg loss: 1.5621\n","main ee avg loss:  0.0967\n","     Test avg time: 0.2412msec; avg val_loss: 1.5097; avg val_acc: 47.06%\n","\tavg val_cost: 10.38%; exits: <9525,88,81,44,5,0,0,0,0,0,257,>\n","saving model:  runs/models/cifar10/eenet110/ee10_fine_conv2_lambda_1.7/model.v6.pt\n","  7:Train avg loss: 1.5330\n","main ee avg loss:  0.0967\n","     Test avg time: 0.2414msec; avg val_loss: 1.5097; avg val_acc: 47.06%\n","\tavg val_cost: 10.38%; exits: <9525,88,81,44,5,0,0,0,0,0,257,>\n","saving model:  runs/models/cifar10/eenet110/ee10_fine_conv2_lambda_1.7/model.v7.pt\n","  8:Train avg loss: 1.5053\n","main ee avg loss:  0.0967\n","     Test avg time: 0.2421msec; avg val_loss: 1.5104; avg val_acc: 47.02%\n","\tavg val_cost: 10.35%; exits: <9525,88,81,44,5,0,4,0,0,0,253,>\n","INFO: Early stopping counter 1 of 5\n","saving model:  runs/models/cifar10/eenet110/ee10_fine_conv2_lambda_1.7/model.v8.pt\n","  9:Train avg loss: 1.4823\n","main ee avg loss:  0.0967\n","     Test avg time: 0.2416msec; avg val_loss: 1.5103; avg val_acc: 47.03%\n","\tavg val_cost: 10.33%; exits: <9525,88,81,44,5,0,7,0,0,0,250,>\n","INFO: Early stopping counter 2 of 5\n","saving model:  runs/models/cifar10/eenet110/ee10_fine_conv2_lambda_1.7/model.v9.pt\n"," 10:Train avg loss: 1.4626\n","main ee avg loss:  0.0967\n","     Test avg time: 0.2416msec; avg val_loss: 1.5111; avg val_acc: 47.00%\n","\tavg val_cost: 10.24%; exits: <9525,88,81,44,5,0,20,0,0,0,237,>\n","INFO: Early stopping counter 3 of 5\n","saving model:  runs/models/cifar10/eenet110/ee10_fine_conv2_lambda_1.7/model.v10.pt\n"," 11:Train avg loss: 1.4476\n","main ee avg loss:  0.0967\n","     Test avg time: 0.2456msec; avg val_loss: 1.5163; avg val_acc: 46.83%\n","\tavg val_cost: 9.95%; exits: <9525,88,81,44,5,0,64,0,0,0,193,>\n","INFO: Early stopping counter 4 of 5\n","saving model:  runs/models/cifar10/eenet110/ee10_fine_conv2_lambda_1.7/model.v11.pt\n"," 12:Train avg loss: 1.4382\n","main ee avg loss:  0.0967\n","     Test avg time: 0.2429msec; avg val_loss: 1.5192; avg val_acc: 46.77%\n","\tavg val_cost: 9.82%; exits: <9525,88,81,44,5,0,76,0,0,0,181,>\n","INFO: Early stopping counter 5 of 5\n","INFO: Early stopping\n","Enabled EE branche  7\n","loss threshold:  0.6\n","  1:Train avg loss: 1.7696\n","main ee avg loss:  0.0967\n","     Test avg time: 0.2417msec; avg val_loss: 1.5567; avg val_acc: 45.38%\n","\tavg val_cost: 7.72%; exits: <9998,2,0,0,0,0,0,0,0,0,0,>\n","saving model:  runs/models/cifar10/eenet110/ee10_fine_conv2_lambda_1.7/model.v1.pt\n","  2:Train avg loss: 1.7180\n","main ee avg loss:  0.0967\n","     Test avg time: 0.2412msec; avg val_loss: 1.5567; avg val_acc: 45.38%\n","\tavg val_cost: 7.72%; exits: <9998,2,0,0,0,0,0,0,0,0,0,>\n","saving model:  runs/models/cifar10/eenet110/ee10_fine_conv2_lambda_1.7/model.v2.pt\n","  3:Train avg loss: 1.6802\n","main ee avg loss:  0.0967\n","     Test avg time: 0.2414msec; avg val_loss: 1.5567; avg val_acc: 45.38%\n","\tavg val_cost: 7.72%; exits: <9998,2,0,0,0,0,0,0,0,0,0,>\n","saving model:  runs/models/cifar10/eenet110/ee10_fine_conv2_lambda_1.7/model.v3.pt\n","  4:Train avg loss: 1.6481\n","main ee avg loss:  0.0967\n","     Test avg time: 0.2419msec; avg val_loss: 1.5567; avg val_acc: 45.38%\n","\tavg val_cost: 7.72%; exits: <9998,2,0,0,0,0,0,0,0,0,0,>\n","saving model:  runs/models/cifar10/eenet110/ee10_fine_conv2_lambda_1.7/model.v4.pt\n","  5:\n","The best avg val_loss: 0.1021, avg val_cost: 99.3438%, avg val_acc: 99.644%\n","\n","The figure is plotted under 'runs/results/cifar10/eenet110/ee10_fine_conv2_lambda_1.7/loss_figure.png'\n","The figure is plotted under 'runs/results/cifar10/eenet110/ee10_fine_conv2_lambda_1.7/acc_cost_figure.png'\n","The figure is plotted under 'runs/results/cifar10/eenet110/ee10_fine_conv2_lambda_1.7/exit_points_std.png'\n"]},{"output_type":"stream","name":"stderr","text":["ERROR:root:Internal Python error in the inspect module.\n","Below is the traceback from this internal error.\n","\n"]},{"output_type":"stream","name":"stdout","text":["The figure is plotted under 'runs/results/cifar10/eenet110/ee10_fine_conv2_lambda_1.7/rel_acc_vs_cost_figure.png'\n","The figure is plotted under 'runs/results/cifar10/eenet110/ee10_fine_conv2_lambda_1.7/acc_vs_flop_figure.png'\n","Traceback (most recent call last):\n","  File \"<ipython-input-13-bc0793d53a57>\", line 40, in run_fw\n","    result.update(train(args, model, train_loader, optimizer, active_exit))\n","  File \"<ipython-input-10-ea2b5233d740>\", line 33, in train\n","    for batch_id, (data, target) in enumerate(train_loader):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 521, in __next__\n","    data = self._next_data()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 561, in _next_data\n","    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n","    data = [self.dataset[idx] for idx in possibly_batched_index]\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n","    data = [self.dataset[idx] for idx in possibly_batched_index]\n","  File \"/usr/local/lib/python3.7/dist-packages/torchvision/datasets/cifar.py\", line 121, in __getitem__\n","    img = self.transform(img)\n","  File \"/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py\", line 61, in __call__\n","    img = t(img)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py\", line 644, in forward\n","    return F.crop(img, i, j, h, w)\n","  File \"/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py\", line 495, in crop\n","    return F_pil.crop(img, top, left, height, width)\n","  File \"/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional_pil.py\", line 221, in crop\n","    return img.crop((left, top, left + width, top + height))\n","  File \"/usr/local/lib/python3.7/dist-packages/PIL/Image.py\", line 1134, in crop\n","    return self._new(self._crop(self.im, box))\n","  File \"/usr/local/lib/python3.7/dist-packages/PIL/Image.py\", line 1148, in _crop\n","    x0, y0, x1, y1 = map(int, map(round, box))\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 3524, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-17-a11b57c5eda9>\", line 10, in <module>\n","    main(mode, writer)\n","  File \"<ipython-input-16-3612041fc74c>\", line 38, in main\n","    run_fw(model, optimizer, lr_scheduler, args, train_loader, test_loader, writer)\n","  File \"<ipython-input-13-bc0793d53a57>\", line 83, in run_fw\n","    sys.exit()\n","SystemExit\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n","    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n","  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n","    return f(*args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n","    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n","  File \"/usr/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n","    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n","AttributeError: 'tuple' object has no attribute 'tb_frame'\n"]},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-bc0793d53a57>\u001b[0m in \u001b[0;36mrun_fw\u001b[0;34m(model, optimizer, lr_scheduler, args, train_loader, test_loader, writer)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactive_exit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_tensorboard\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-10-ea2b5233d740>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args, model, train_loader, optimizer, active_exit)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m#for batch_id, ((data, noise), target) in enumerate(train_loader):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;31m# fetch the current batch data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mcrop\u001b[0;34m(img, top, left, height, width)\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF_pil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional_pil.py\u001b[0m in \u001b[0;36mcrop\u001b[0;34m(img, top, left, height, width)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mcrop\u001b[0;34m(self, box)\u001b[0m\n\u001b[1;32m   1133\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1134\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_crop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36m_crop\u001b[0;34m(self, im, box)\u001b[0m\n\u001b[1;32m   1147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1148\u001b[0;31m         \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: ","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)","    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n","\u001b[0;32m<ipython-input-17-a11b57c5eda9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_ee\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-16-3612041fc74c>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(mode, writer)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m#train_loader, test_loader = load_data_serialized(args)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mrun_fw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-13-bc0793d53a57>\u001b[0m in \u001b[0;36mrun_fw\u001b[0;34m(model, optimizer, lr_scheduler, args, train_loader, test_loader, writer)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0;31m# print the best validation result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mSystemExit\u001b[0m: ","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2080\u001b[0m                            'the full traceback.\\n']\n\u001b[1;32m   2081\u001b[0m                     stb.extend(self.InteractiveTB.get_exception_only(etype,\n\u001b[0;32m-> 2082\u001b[0;31m                                                                      value))\n\u001b[0m\u001b[1;32m   2083\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2084\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mget_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mexception\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \"\"\"\n\u001b[0;32m--> 754\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mListTB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructured_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshow_exception_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    631\u001b[0m                     chained_exceptions_tb_offset, context)\n\u001b[1;32m    632\u001b[0m                 \u001b[0;34m+\u001b[0m \u001b[0mchained_exception_message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m                 + out_list)\n\u001b[0m\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1368\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1268\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m             )\n\u001b[1;32m   1270\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Minimal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m-> 1125\u001b[0;31m                                                                tb_offset)\n\u001b[0m\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[0;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"]}],"source":["tensorboard_dir = 'runs/eenet_experiment_1'\n","if os.path.exists(tensorboard_dir):\n","    shutil.rmtree(tensorboard_dir)\n","writer = SummaryWriter(tensorboard_dir)\n","%load_ext tensorboard\n","%tensorboard --logdir runs/eenet_experiment_1\n","decrease_font()\n","\n","mode = Mode.train_ee\n","main(mode, writer)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"colab_train_eenet_inc.ipynb","provenance":[],"machine_shape":"hm"},"interpreter":{"hash":"31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"},"kernelspec":{"display_name":"Python 3.7.12 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"metadata":{"interpreter":{"hash":"4cd7ab41f5fca4b9b44701077e38c5ffd31fe66a6cab21e0214b68d958d0e462"}}},"nbformat":4,"nbformat_minor":0}
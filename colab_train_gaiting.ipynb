{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":51200,"status":"ok","timestamp":1643482283200,"user":{"displayName":"Assaf La","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUaXBQVi1i3pv_IG6dyzlsX7aSwxWMcT_iQuRs8no=s64","userId":"07226046456222457646"},"user_tz":0},"id":"OMIVlc1Bg_4M","outputId":"b3fcbfb7-b745-4a74-8b60-23627db0ec6f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1200,"status":"ok","timestamp":1643482284400,"user":{"displayName":"Assaf La","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUaXBQVi1i3pv_IG6dyzlsX7aSwxWMcT_iQuRs8no=s64","userId":"07226046456222457646"},"user_tz":0},"id":"ZMRxQXMsRamB","outputId":"ab46093a-19fd-4dbc-ca6b-1445b44a294f"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/afeka/Project/code/PTEEnet/PTEEnet\n"]}],"source":["#@title cd\n","%pwd\n","%cd /content/drive/MyDrive/afeka/Project/code/PTEEnet/PTEEnet"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":6000,"status":"ok","timestamp":1643482290400,"user":{"displayName":"Assaf La","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUaXBQVi1i3pv_IG6dyzlsX7aSwxWMcT_iQuRs8no=s64","userId":"07226046456222457646"},"user_tz":0},"id":"UVXtOWnTB_MB","colab":{"base_uri":"https://localhost:8080/"},"outputId":"45688903-c5b7-4d78-e893-1b3cd254e5cf"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 792 kB 9.9 MB/s \n","\u001b[K     |████████████████████████████████| 375 kB 63.1 MB/s \n","\u001b[?25h  Building wheel for ipdb (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you have prompt-toolkit 3.0.26 which is incompatible.\n","google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.31.1 which is incompatible.\u001b[0m\n"]}],"source":["#@title install packages\n","#%pip install chainer\n","%pip install -Uqq ipdb"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":0,"status":"ok","timestamp":1643482290400,"user":{"displayName":"Assaf La","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUaXBQVi1i3pv_IG6dyzlsX7aSwxWMcT_iQuRs8no=s64","userId":"07226046456222457646"},"user_tz":0},"id":"fOMPfWSZhFlH","outputId":"a69b16c8-ecad-4dd0-e699-71b4576a62a5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Sat Jan 29 18:51:29 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   38C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n","Your runtime has 27.3 gigabytes of available RAM\n","\n","You are using a high-RAM runtime!\n"]}],"source":["#@title read gpu details\n","#import chainer\n","#chainer.print_runtime_info()\n","\n","#print('GPU availability:', chainer.cuda.available)\n","#print('cuDNN availablility:', chainer.cuda.cudnn_enabled)\n","gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n","  print('and then re-execute this cell.')\n","else:\n","  print(gpu_info)\n","\n","from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n","  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n","  print('re-execute this cell.')\n","else:\n","  print('You are using a high-RAM runtime!')"]},{"cell_type":"code","execution_count":5,"metadata":{"cellView":"form","executionInfo":{"elapsed":9500,"status":"ok","timestamp":1643482299900,"user":{"displayName":"Assaf La","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUaXBQVi1i3pv_IG6dyzlsX7aSwxWMcT_iQuRs8no=s64","userId":"07226046456222457646"},"user_tz":0},"id":"YxxBGSa5UqrP"},"outputs":[],"source":["#@title imports\n","\"\"\"\n","high level support for doing this and that.\n","\"\"\"\n","from __future__ import print_function\n","import time\n","import csv\n","import numpy as np\n","import torch\n","import torch.nn.functional as F\n","from scipy import stats\n","from init import initializer\n","from eenet import EENet\n","from custom_eenet import CustomEENet\n","from gatednet import GatedNet\n","import matplotlib.pylab as plt\n","import loss_functions\n","import utils\n","import config\n","import gc\n","import sys\n","import math\n","import os\n","from torch.utils.tensorboard import SummaryWriter\n","import torchvision.transforms.functional as tf\n","import matplotlib.pyplot as plt\n","import ipdb\n","\n","#import xgboost as xgb\n","#from sklearn.metrics import confusion_matrix, classification_report\n","#from sklearn.metrics import accuracy_score\n","#import joblib as jobl\n","from collections import Counter\n","from matplotlib import pyplot\n","from numpy import where\n","#from imblearn.over_sampling import RandomOverSampler \n","#from imblearn.under_sampling import RandomUnderSampler\n","from imblearn.over_sampling import SMOTE\n","from sklearn.model_selection import train_test_split\n","#from xgboost.sklearn import XGBRegressor\n","\n","%matplotlib inline\n"]},{"cell_type":"code","execution_count":6,"metadata":{"cellView":"form","executionInfo":{"elapsed":0,"status":"ok","timestamp":1643482299900,"user":{"displayName":"Assaf La","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUaXBQVi1i3pv_IG6dyzlsX7aSwxWMcT_iQuRs8no=s64","userId":"07226046456222457646"},"user_tz":0},"id":"ybzxK0yeUAOw"},"outputs":[],"source":["#@title train_gated_xgboost\n","\"\"\"\n","params={\n","'booster':'gbtree',\n","'objective': 'multi:softmax',\n","'num_class':11,\n","'gamma':0.6,#0.1,\n","'max_depth':10, #6\n","'lambda': 3,#2,\n","'alpha': 4, #new\n","'subsample':0.7,\n","'colsample_bytree':0.7,\n","'min_child_weight':1,\n","'silent':0 ,\n","'eta': 0.01, #0.01\n","'seed':1000,\n","'tree_method': 'gpu_hist',\n","'gpu_id': 0,\n","}\n","\"\"\"\n","depth = 8\n","params={\n","'booster':'gbtree',\n","'objective': 'multi:softmax',\n","'num_class':11,\n","'gamma':0.6,#0.1,\n","'max_depth':depth, #6\n","'lambda': 3,#2,\n","'alpha': 4, #new\n","'subsample':0.7,\n","'colsample_bytree':0.7,\n","'min_child_weight':1,\n","'silent':0 ,\n","'eta': 0.03, #0.01\n","'seed':1000,\n","'tree_method': 'gpu_hist',\n","'gpu_id': 0,\n","}\n","\n","#82%\n","\n","def evaluate(model, X, Y):#, weights):\n","    predicted_Y = model.predict(X)\n","    #ipdb.set_trace(context=6)\n","    print(predicted_Y)\n","    accuracy = accuracy_score(Y, predicted_Y)#, weights)\n","    return accuracy\n","\"\"\"\n","def produce_weights(data, size, num_of_classes):\n","    counter = Counter(data)\n","    weights = np.zeros(num_of_classes)\n","    weights_vec = np.zeros(size)\n","    for key in counter:\n","        #print(key)\n","        weights[int(key)] = counter[key]\n","    weights = 1 - weights / np.max(weights) + 0.001\n","    #ipdb.set_trace(context=6)\n","    #print(weights)\n","    for i, value in enumerate(data):\n","        weights_vec[i] = weights[value]\n","    return weights_vec\n","\"\"\" \n","\n","def train_gated_xgboost(args, noise_levels):\n","    log_file = open(args.gated_models_dir+'/train_gated_xgboost_log.txt', 'a', newline='')\n","    log_file.write(\"Training gated xgboost mode:\\n\")\n","    log_file.write(\"loss threshold: \" + str(args.loss_threshold) + \", SNR=\" + str(args.noise_snr) + \"\\n\")\n","    \n","    %matplotlib inline\n","\n","    type_loader = 'test'\n","    ground_truth_noisy_dir = args.ground_truths_dir + '/' + str(args.loss_threshold)# + '/' + 'snr_' + str(noise_levels[0])\n","    \"\"\"\n","    data_file_train = ground_truth_noisy_dir + '/datas_train.' + str(args.loss_threshold) + '.pt'\n","    data_train = torch.load(data_file_train)\n","    print('loaded data train at: ', data_file_train)\n","    \n","    gt_file_train = ground_truth_noisy_dir + '/exit_idx_predictions_train.' + str(args.loss_threshold) + '.pt'\n","    exits_ground_truth_train = torch.load(gt_file_train)\n","    print('loaded exits ground truths train at: ', gt_file_train)\n","    \"\"\"\n","    data_file_test = ground_truth_noisy_dir + '/datas_' + type_loader + '.' + str(args.loss_threshold) + '.pt'\n","    data_test = torch.load(data_file_test)\n","    print('loaded data test at: ', data_file_test)\n","    \n","    gt_file_test = ground_truth_noisy_dir + '/exit_idx_predictions_' + type_loader + '.' + str(args.loss_threshold) + '.pt'\n","    exits_ground_truth_test = torch.load(gt_file_test)\n","    print('loaded exits ground truths test at: ', gt_file_test)\n","    \n","    if 0:\n","        for m in range(args.num_noise_levels-1):\n","            ground_truth_noisy_dir = args.ground_truths_dir + '/' + str(args.loss_threshold) + '/' + 'snr_' + str(noise_levels[m+1])\n","            \"\"\"\n","            data_file_train = ground_truth_noisy_dir + '/datas_train.' + str(args.loss_threshold) + '.pt'\n","            data = torch.load(data_file_train)\n","            print('loaded data train at: ', data_file_train)\n","            data_train = np.concatenate((data_train, data), axis=0)\n","\n","            gt_file_train = ground_truth_noisy_dir + '/exit_idx_predictions_train.' + str(args.loss_threshold) + '.pt'\n","            data = torch.load(gt_file_train)\n","            print('loaded exits ground truths train at: ', gt_file_train)\n","            exits_ground_truth_train = np.concatenate((exits_ground_truth_train, data), axis=0)\n","            \"\"\"\n","            data_file_test = ground_truth_noisy_dir + '/datas_' + type_loader + '.' + str(args.loss_threshold) + '.pt'\n","            data = torch.load(data_file_test)\n","            print('loaded data test at: ', data_file_test)\n","            data_test = np.concatenate((data_test, data), axis=0)\n","\n","            gt_file_test = ground_truth_noisy_dir + '/exit_idx_predictions_' + type_loader + '.' + str(args.loss_threshold) + '.pt'\n","            data = torch.load(gt_file_test)\n","            print('loaded exits ground truths test at: ', gt_file_test)\n","            exits_ground_truth_test = np.concatenate((exits_ground_truth_test, data), axis=0)\n","        \n","    \"\"\"\n","    ipdb.set_trace(context=6)\n","    gt_file_train = args.ground_truths_dir + '/exit_idx_predictions_train.' + str(args.loss_threshold) + '.pt'\n","    exits_ground_truth_train = torch.load(gt_file_train)\n","    print('loaded exits ground truths at: ', gt_file_train)\n","    train_len = len(exits_ground_truth_train)\n","    #print('exits_ground_truth_train {:8d}'.format(train_len))\n","    \n","    gt_file_test = args.ground_truths_dir + '/exit_idx_predictions_test.' + str(args.loss_threshold) + '.pt'\n","    exits_ground_truth_test = torch.load(gt_file_test)\n","    print('loaded exits ground truths at: ', gt_file_test)\n","    test_len = len(exits_ground_truth_test)\n","    #print('exits_ground_truth_test {:8d}'.format(test_len))\n","    \n","    data_file_train = args.ground_truths_dir + '/datas_train.' + str(args.loss_threshold) + '.pt'\n","    data_train = torch.load(data_file_train)\n","    print('loaded data train at: ', data_file_train)\n","    data_train_len = len(data_train)\n","    #print('data_train_len {:8d}'.format(data_train_len))\n","    \n","    data_file_test = args.ground_truths_dir + '/datas_test.' + str(args.loss_threshold) + '.pt'\n","    data_test = torch.load(data_file_test)\n","    print('loaded data test at: ', data_file_test)\n","    data_test_len = len(data_test)\n","    #print('data_test_len {:8d}'.format(data_test_len))\n","    \"\"\"\n","    #ipdb.set_trace(context=6)\n","    #data_train = torch.stack(data_train, dim=0)\n","    #data_test = torch.stack(data_test, dim=0)\n","    #d1, d2, d3, d4 = data_train.shape\n","    #data_train = data_train.reshape((d1, d2*d3*d4))\n","    d1, d2, d3, d4 = data_test.shape\n","    data_test = data_test.reshape((d1, d2*d3*d4))\n","    #data_train = torch.flatten(torch.from_numpy(data_train), start_dim=1)\n","    #data_test = torch.flatten(torch.from_numpy(data_test), start_dim=1)\n","\n","    #data_train = data_train.cpu().detach().numpy()\n","    #data_test = data_test.cpu().detach().numpy()\n","    #exits_ground_truth_train = np.array(exits_ground_truth_train)\n","    exits_ground_truth_test = np.array(exits_ground_truth_test)\n","    #ipdb.set_trace(context=6)\n","    ros_over = RandomOverSampler(random_state=42)\n","    ros_under = RandomUnderSampler(random_state=42)\n","    sm = SMOTE(random_state=42)\n","    \n","    #data_train, exits_ground_truth_train = ros_over.fit_resample(data_train, exits_ground_truth_train)\n","    #data_test, exits_ground_truth_test = ros_over.fit_resample(data_test, exits_ground_truth_test)\n","    #data_train, exits_ground_truth_train = sm.fit_resample(data_train, exits_ground_truth_train)\n","    print('Resampled test dataset shape before %s' % Counter(exits_ground_truth_test))\n","\n","    data_test, exits_ground_truth_test = sm.fit_resample(data_test, exits_ground_truth_test)\n","    #print('Resampled train dataset shape %s' % Counter(exits_ground_truth_train))\n","    print('Resampled test dataset shape %s' % Counter(exits_ground_truth_test))\n","\n","    X_train, X_test, y_train, y_test = train_test_split(data_test, exits_ground_truth_test, test_size=0.33, random_state=42)\n","    data_test = None\n","    exits_ground_truth_test = None\n","    \n","    #ipdb.set_trace(context=6)\n","    \n","    #xgb_train = xgb.DMatrix(X_train, label=y_train)#, weight=weights_vec_train)\n","    #xgb_val = xgb.DMatrix(X_test, label=y_test)#, weight=weights_vec_test)\n","    #watchlist = [(xgb_train, 'train'), (xgb_val, 'val')]\n","    \n","    num_rounds = 1500\n","    #depth = 4\n","    # Training phase\n","    print(\"building model...\")\n","    XGB = XGBRegressor(tree_method = \"gpu_hist\", objective = \"multi:softmax\", num_class=11,\\\n","                       single_precision_histogram=True, max_depth=args.max_depth, eval_metric=[\"merror\"],\\\n","                       n_estimators=num_rounds, verbosity=1)\n","    #print(XGB)\n","    eva_set = [(X_test, y_test)]\n","    X_test = None\n","    y_test = None\n","    #ipdb.set_trace(context=6)\n","    \n","    #XGB = XGB.fit(X_train, y_train, eval_metric=\"auc\", early_stopping_rounds=100, verbose=True)\n","    XGB = XGB.fit(X_train, y_train, verbose=True, early_stopping_rounds=5, eval_set=eva_set)\n","    #score = XGB.score(X_train, y_train)  \n","    #print(\"Training score: \", score)\n","    #plst = list(params.items())\n","    #gbm = xgb.train(plst, xgb_train, num_rounds, watchlist,early_stopping_rounds=100)\n","    print(\"saving model...\")\n","    log_file.write(\"saving model...\\n\")\n","    XGB.save_model(args.gated_models_dir + '/xg_model.' + str(args.loss_threshold) + '.depth' + str(args.max_depth) + '.json')\n","    #jobl.dump(gbm, args.gated_models_dir + '/xg_model.' + str(args.loss_threshold) + '.bin')\n","    #validation_accuracy = evaluate(gbm, xgb_val, y_test)#, weights_vec_test)\n","    #validation_accuracy = evaluate(XGB, X_test, y_test)#, weights_vec_test)\n","    \n","    #print(\"  - validation accuracy = {0:.4f}\".format(validation_accuracy))\n","    #log_file.write(\"validation accuracy: \" + str(validation_accuracy) + \"\\n\")\n","    log_file.close()\n","    return\n","    #return validation_accuracy"]},{"cell_type":"code","execution_count":7,"metadata":{"cellView":"code","executionInfo":{"elapsed":0,"status":"ok","timestamp":1643482299900,"user":{"displayName":"Assaf La","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUaXBQVi1i3pv_IG6dyzlsX7aSwxWMcT_iQuRs8no=s64","userId":"07226046456222457646"},"user_tz":0},"id":"g64rxk8VxyEw"},"outputs":[],"source":["#@title load_generated_data\n","from torch.utils.data import Dataset, TensorDataset, DataLoader\n","\n","class CustomTensorDataset(Dataset):\n","    \"\"\"TensorDataset with support of transforms.\n","    \"\"\"\n","    def __init__(self, tensors, transform=None):\n","        #ipdb.set_trace(context=6)\n","        assert all(tensors[0].size(0) == tensor.size(0) for tensor in tensors)\n","        self.tensors = tensors\n","        self.transform = transform\n","\n","    def __getitem__(self, index):\n","        x = self.tensors[0][index]\n","\n","        if self.transform:\n","            x = self.transform(x)\n","\n","        y = self.tensors[1][index]\n","        \n","        return x, y\n","\n","    def __len__(self):\n","        return self.tensors[0].size(0)\n","\n","def smote_data(data, target, return_to_org_shape=False):\n","    sm = SMOTE(random_state=42)\n","    \n","    d1, d2, d3, d4 = data.shape\n","    data = data.reshape((d1, d2*d3*d4))\n","    print('Resampled dataset shape before %s' % Counter(target))\n","    data, target = sm.fit_resample(data, target)\n","    print('Resampled dataset shape %s' % Counter(target))\n","\n","    #ipdb.set_trace(context=6) \n","    if return_to_org_shape:\n","        d1, d5 = data.shape\n","        data = data.reshape((d1, d2, d3, d4))   \n","\n","    return data, target\n","    \n","        \n","def load_generated_data(args, smote, return_to_org_shape=False):\n","    ground_truth_noisy_dir = args.ground_truths_dir + '/' + str(args.loss_threshold)# + '/' + 'snr_' + str(noise_levels[0])\n","    \n","    data_file_train = ground_truth_noisy_dir + '/datas_train.' + str(args.loss_threshold) + '.pt'\n","    data_train = torch.load(data_file_train)\n","    print('loaded data train at: ', data_file_train)\n","    \n","    data_file_test = ground_truth_noisy_dir + '/datas_test.' + str(args.loss_threshold) + '.pt'\n","    data_test = torch.load(data_file_test)\n","    print('loaded data test at: ', data_file_test)\n","    \n","    gt_file_train = ground_truth_noisy_dir + '/exit_idx_predictions_train.' + str(args.loss_threshold) + '.pt'\n","    exits_ground_truth_train = torch.load(gt_file_train)\n","    print('loaded exits ground truths train at: ', gt_file_train)\n","    \n","    gt_file_test = ground_truth_noisy_dir + '/exit_idx_predictions_test.' + str(args.loss_threshold) + '.pt'\n","    exits_ground_truth_test = torch.load(gt_file_test)\n","    print('loaded exits ground truths test at: ', gt_file_test)\n","\n","    if smote:\n","        data_train, exits_ground_truth_train = smote_data(data_train, exits_ground_truth_train, return_to_org_shape)\n","    else:\n","        d1, d2, d3, d4 = data_train.shape\n","        data_train = data_train.reshape((d1, d2*d3*d4))        \n","    \n","    data_train, data_test, exits_ground_truth_train, exits_ground_truth_test = train_test_split(data_train,\\\n","                                                                                                exits_ground_truth_train, test_size=0.2, random_state=42)\n","    \n","    data_train, target_train = torch.from_numpy(data_train), torch.from_numpy(exits_ground_truth_train)    \n","    data_test, target_test = torch.from_numpy(data_test), torch.from_numpy(exits_ground_truth_test)\n","    \n","    train_set = CustomTensorDataset(tensors=(data_train, target_train))    \n","    validation_set = CustomTensorDataset(tensors=(data_test, target_test))\n","    loader_train = torch.utils.data.DataLoader(train_set, batch_size=args.batch_size, shuffle=args.shuffle_train)\n","    loader_val = torch.utils.data.DataLoader(validation_set, batch_size=args.test_batch, shuffle=args.shuffle_test)\n","\n","    return loader_train, loader_val"]},{"cell_type":"code","execution_count":8,"metadata":{"cellView":"code","executionInfo":{"elapsed":600,"status":"ok","timestamp":1643482300500,"user":{"displayName":"Assaf La","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUaXBQVi1i3pv_IG6dyzlsX7aSwxWMcT_iQuRs8no=s64","userId":"07226046456222457646"},"user_tz":0},"id":"CeZ2Q0S4foIz"},"outputs":[],"source":["#@title train_gating_model\n","from gatednet import gnet, gnet_s, gnet_l, gnet_v\n","import torch.optim as optim\n","import torch.nn as nn\n","import shutil\n","from early_stopping import early_stop\n","import densenet as dn\n","\n","\n","def accuracy(output, target, topk=(1,)):\n","    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n","    maxk = max(topk)\n","    batch_size = target.size(0)\n","\n","    _, pred = output.topk(maxk, 1, True, True)\n","    pred = pred.t()\n","    correct = pred.eq(target.view(1, -1).expand_as(pred))\n","\n","    res = []\n","    for k in topk:\n","        correct_k = correct[:k].view(-1).float().sum(0)\n","        res.append(correct_k.mul_(100.0 / batch_size))\n","    return res\n","        \n","def train_gating_model(args, writer):    \n","    \n","    log_file = open(args.gated_models_dir+'/train_gated_nn_log.txt', 'a', newline='')\n","    log_file.write(\"Training gated nn mode:\\n\")\n","    log_file.write(\"loss threshold: \" + str(args.loss_threshold) + \"\\n\")\n","    \n","    %matplotlib inline\n","\n","    loader_train, loader_test = load_generated_data(args, smote=True, return_to_org_shape=True)\n","    #model = gnet((3, 32, 32), args.num_ee + 1, args.filters)\n","    #model = gnet_s((3, 32, 32), args.num_ee + 1, args.filters)\n","    model = gnet_v((3, 32, 32), args.num_ee + 1)\n","    # create model\n","    #model = dn.DenseNet3(15,#args.layers, \n","    #                     11, \n","    #                     12,#args.growth, \n","    #                     reduction=1,#args.reduce,\n","    #                     bottleneck=0,#args.bottleneck, \n","    #                     dropRate=0)#args.droprate)\n","    #model = gnet_l(3*32*32, args.num_ee + 1)\n","    #ipdb.set_trace(context=6) \n","    early_stopping = early_stop(patience=7)\n","    \n","    #args.device = 'cpu'\n","    model = model.to(args.device)\n","    if args.optimizer == 'SGD':\n","        optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum,\n","                              weight_decay=args.weight_decay,\n","                              nesterov=True)\n","    else:\n","        optimizer = optim.Adam(model.parameters(), lr=args.lr)\n","    #criterion = nn.CrossEntropyLoss()\n","        \n","    print('Running for {:5d} epochs'.format(args.epochs))\n","    try:    \n","        torch.cuda.empty_cache()\n","        #ipdb.set_trace(context=6) \n","                    \n","        for epoch in range(1, args.epochs + 1):\n","            print('{:3d}:'.format(epoch), end='')\n","            losses = []\n","            model.train()\n","            for batch_id, (data, target) in enumerate(loader_train):\n","                data, target = data.to(args.device), target.to(args.device, dtype=torch.int64)\n","                \n","                #ipdb.set_trace(context=6) \n","                pred = model(data)\n","                #writer.add_graph(model, data)\n","    \n","                #loss = criterion(pred, target)\n","                loss = F.nll_loss(pred.log(), target)\n","                optimizer.zero_grad()\n","                loss.backward()\n","                optimizer.step()\n","\n","                losses.append(float(loss))\n","                  \n","            train_epoch_loss = round(np.mean(losses), 4)\n","            print('Train avg loss: {:.4f}'.format(train_epoch_loss))\n","            writer.add_scalar(\"Train/Loss\", train_epoch_loss, epoch)\n","            for name, weight in model.named_parameters():\n","                writer.add_histogram(name,weight, epoch)\n","                #writer.add_histogram(f'{name}.grad',weight.grad, epoch)\n","                \n","            if epoch % 1 == 0:\n","                accs = []\n","                val_losses = []\n","                records = []\n","            \n","                model.eval()\n","                starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n","                with torch.no_grad():\n","                    for batch_id, (data, target) in enumerate(loader_test):\n","                        data, target = data.to(args.device), target.to(args.device, dtype=torch.int64)\n","                        #ipdb.set_trace(context=6) \n","                        starter.record()\n","                        pred = model(data)\n","                        ender.record()\n","                        torch.cuda.synchronize()\n","                        record = starter.elapsed_time(ender)\n","                        #loss = criterion(pred, target)\n","                        loss = F.nll_loss(pred.log(), target)\n","                        prec1 = accuracy(pred.float().data, target)[0]\n","                        \n","                        accs.append(float(prec1))\n","                        val_losses.append(float(loss))\n","                        records.append(float(record/args.test_batch))\n","                        #ipdb.set_trace(context=6)                         \n","                        \n","                    #ipdb.set_trace(context=6) \n","                    print('\\tValidation avg loss: {:.4f}, Avg test acc is: {:.2f}%, time: {:.4f}ms'.format(round(np.mean(val_losses), 4),\\\n","                                                                                                           round(np.mean(accs), 4),\\\n","                                                                                                           round(np.mean(records), 4)))\n","                    val_epoch_loss = round(np.mean(val_losses), 4)\n","                    writer.add_scalar(\"Validation/Loss\", val_epoch_loss, epoch)\n","                    writer.add_scalar(\"Validation/Accuracy\", round(np.mean(accs), 4), epoch)                \n","                    writer.add_scalar(\"Validation/Time\", round(np.mean(records), 4), epoch)                \n","\n","                    early_stopping(val_epoch_loss)\n","                    if early_stopping.early_stop:\n","                        break\n","                \n","                    accs = None\n","                    val_losses = None\n","                    records = None\n","\n","            writer.flush()\n","        writer.close()\n","\n","    except KeyboardInterrupt:\n","        print('exception')\n","        writer.close()\n","        sys.exit()\n","    \n","    \n","    filename = 'gated_models/' + str(args.dataset) + '/model.' + str(args.loss_threshold) + '.pt'\n","    print('saving gated model: ', filename)\n","    torch.save(model, filename)"]},{"cell_type":"code","execution_count":9,"metadata":{"cellView":"form","executionInfo":{"elapsed":500,"status":"ok","timestamp":1643482301000,"user":{"displayName":"Assaf La","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUaXBQVi1i3pv_IG6dyzlsX7aSwxWMcT_iQuRs8no=s64","userId":"07226046456222457646"},"user_tz":0},"id":"TiAPblzAGeLz"},"outputs":[],"source":["#@title main\n","\n","\"\"\"Main function of the program.\n","\n","The function loads the dataset and calls training and validation functions.\n","\"\"\"\n","%load_ext autoreload\n","%autoreload 2\n","\n","import importlib\n","importlib.reload(config)\n","importlib.reload(loss_functions)\n","importlib.reload(utils)\n","from enum import Enum\n","\n","class Mode(Enum):\n","    train_main = 0\n","    train_ee = 1\n","    generate_exits_gt = 2 \n","    train_gating = 3\n","    generate_relative_loss = 4 \n","    plot_relative_loss = 5\n","    calc_relative_time = 6\n","\n","def main(mode: Mode, writer):\n","    print(mode.value)\n","    args = config.args_global\n","    args += config.argu[mode.value]\n","    %pwd\n","    model, optimizer, lr_scheduler, args = initializer(args)\n","    print(args)\n","    #ipdb.set_trace(context=6) \n","    \n","    \n","    if mode == Mode.train_gating:\n","        print('Training Gated model')\n","        accus = []\n","        for thresh in range(2, 22, 3):\n","            args.loss_threshold = thresh/10\n","            val_accu = train_gating_model(args, writer)\n","            accus.append(val_accu)\n","        print('val_accuracies: ', np.array(accus))\n","        #train_gating_model(args, model, train_loader, test_loader, trainset)\n","    \n","    print('Finished')"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":330000,"status":"error","timestamp":1643482631000,"user":{"displayName":"Assaf La","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUaXBQVi1i3pv_IG6dyzlsX7aSwxWMcT_iQuRs8no=s64","userId":"07226046456222457646"},"user_tz":0},"id":"v9gjbi-OCQ2J","outputId":"2b4e9b02-4c13-4fc0-c186-5a3376fe0929"},"outputs":[{"output_type":"stream","name":"stdout","text":["3\n","use cuda:  True  device:  cuda\n","full_flow False\n","last model found and loaded:  runs/models/cifar10/eenet110/ee10_fine_conv2_lambda_1.0/model.v4.pt\n","ee-block-0: flops=19.78 MMac, params=19.34 k, cost-rate=0.08\n","ee-block-1: flops=34.23 MMac, params=33.35 k, cost-rate=0.13\n","ee-block-2: flops=43.86 MMac, params=42.7 k, cost-rate=0.17\n","ee-block-3: flops=53.49 MMac, params=52.04 k, cost-rate=0.21\n","ee-block-4: flops=63.13 MMac, params=61.39 k, cost-rate=0.25\n","ee-block-5: flops=72.76 MMac, params=70.73 k, cost-rate=0.28\n","ee-block-6: flops=82.4 MMac, params=80.08 k, cost-rate=0.32\n","ee-block-7: flops=92.03 MMac, params=89.42 k, cost-rate=0.36\n","ee-block-8: flops=100.48 MMac, params=136.57 k, cost-rate=0.39\n","ee-block-9: flops=110.01 MMac, params=173.69 k, cost-rate=0.43\n","exit-block: flops=256.32 MMac, params=1.73 M, cost-rate=1.00\n","Namespace(adaptive_lr=False, add_noise=False, batch_size=128, clear_dirs=False, dataset='cifar10', device=device(type='cuda'), distribution='fine', ee_costs=None, epochs=300, exit_type='conv2', filters=4, gated_models_dir='gated_models/cifar10/no_noise', ground_truths_dir='gated_ground_truths/cifar10', hist_file=<_io.TextIOWrapper name='runs/results/cifar10/eenet110/ee10_fine_conv2_lambda_1.0/history.csv' mode='a' encoding='UTF-8'>, input_shape=(3, 32, 32), lambda_coef=1.0, load_model=None, log_interval=1, loss_func='v2', loss_main=0, loss_threshold=0.2, lr=0.001, max_depth=10, max_noise_snr=30, min_noise_snr=-5, model='eenet110', models_dir='runs/models/cifar10/eenet110/ee10_fine_conv2_lambda_1.0', momentum=0.9, multi_gpu=False, no_cuda=False, no_save_model=False, no_tensorboard=False, noise_snr=0, noise_str='no_noise', num_classes=10, num_ee=10, num_noise_levels=5, optimizer='SGD', plot_history=False, recorder=<_csv.writer object at 0x7f33d3a85a70>, relative_losses_dir='relative_losses/cifar10/no_noise', results_dir='runs/results/cifar10/eenet110/ee10_fine_conv2_lambda_1.0', save_best=False, seed=1, shuffle_test=False, shuffle_train=False, start_epoch=5, test_batch=128, two_stage=False, use_main_targets=False, validate=True, weight_decay=0.0001)\n","Training Gated model\n","loaded data train at:  gated_ground_truths/cifar10/0.2/datas_train.0.2.pt\n","loaded data test at:  gated_ground_truths/cifar10/0.2/datas_test.0.2.pt\n","loaded exits ground truths train at:  gated_ground_truths/cifar10/0.2/exit_idx_predictions_train.0.2.pt\n","loaded exits ground truths test at:  gated_ground_truths/cifar10/0.2/exit_idx_predictions_test.0.2.pt\n","Resampled dataset shape before Counter({0.0: 15848, 8.0: 9569, 10.0: 7732, 1.0: 5260, 9.0: 2627, 2.0: 2477, 3.0: 1960, 5.0: 1256, 4.0: 1238, 6.0: 1154, 7.0: 879})\n","Resampled dataset shape Counter({3.0: 15848, 0.0: 15848, 10.0: 15848, 8.0: 15848, 5.0: 15848, 1.0: 15848, 6.0: 15848, 2.0: 15848, 4.0: 15848, 7.0: 15848, 9.0: 15848})\n","Building V Gated Net\n","Running for   300 epochs\n","  1:Train avg loss: 2.3883\n","\tValidation avg loss: 2.3753, Avg test acc is: 12.75%, time: 0.0238ms\n","  2:Train avg loss: 2.3445\n","\tValidation avg loss: 2.2984, Avg test acc is: 16.85%, time: 0.0239ms\n","  3:Train avg loss: 2.2865\n","\tValidation avg loss: 2.2663, Avg test acc is: 18.78%, time: 0.0238ms\n","  4:Train avg loss: 2.2526\n","\tValidation avg loss: 2.2323, Avg test acc is: 20.86%, time: 0.0238ms\n","  5:Train avg loss: 2.2084\n","\tValidation avg loss: 2.1808, Avg test acc is: 23.95%, time: 0.0238ms\n","  6:Train avg loss: 2.1371\n","\tValidation avg loss: 2.0873, Avg test acc is: 29.34%, time: 0.0237ms\n","  7:Train avg loss: 2.0128\n","\tValidation avg loss: 1.9278, Avg test acc is: 35.93%, time: 0.0237ms\n","  8:Train avg loss: 1.8078\n","\tValidation avg loss: 1.6786, Avg test acc is: 44.65%, time: 0.0237ms\n","  9:Train avg loss: 1.5422\n","\tValidation avg loss: 1.3984, Avg test acc is: 54.15%, time: 0.0239ms\n"," 10:Train avg loss: 1.2657\n","\tValidation avg loss: 1.1438, Avg test acc is: 62.44%, time: 0.0237ms\n"," 11:Train avg loss: 1.0264\n","\tValidation avg loss: 0.9424, Avg test acc is: 68.47%, time: 0.0237ms\n"," 12:Train avg loss: 0.8351\n","\tValidation avg loss: 0.8146, Avg test acc is: 72.60%, time: 0.0239ms\n"," 13:Train avg loss: 0.6869\n","\tValidation avg loss: 0.7078, Avg test acc is: 76.18%, time: 0.0238ms\n"," 14:Train avg loss: 0.5740\n","\tValidation avg loss: 0.6646, Avg test acc is: 77.63%, time: 0.0237ms\n"," 15:Train avg loss: 0.4805\n","\tValidation avg loss: 0.5968, Avg test acc is: 80.08%, time: 0.0238ms\n"," 16:Train avg loss: 0.4049\n","\tValidation avg loss: 0.5719, Avg test acc is: 81.38%, time: 0.0238ms\n"," 17:Train avg loss: 0.3438\n","\tValidation avg loss: 0.5510, Avg test acc is: 82.43%, time: 0.0237ms\n"," 18:Train avg loss: 0.2921\n","\tValidation avg loss: 0.5366, Avg test acc is: 83.43%, time: 0.0239ms\n"," 19:Train avg loss: 0.2477\n","\tValidation avg loss: 0.5546, Avg test acc is: 83.86%, time: 0.0237ms\n","INFO: Early stopping counter 1 of 7\n"," 20:exception\n"]},{"output_type":"error","ename":"SystemExit","evalue":"ignored","traceback":["An exception has occurred, use %tb to see the full traceback.\n","\u001b[0;31mSystemExit\u001b[0m\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n","  \n"]}],"source":["tensorboard_dir = 'runs/gated_experiment_1'\n","if os.path.exists(tensorboard_dir):\n","    shutil.rmtree(tensorboard_dir)\n","writer = SummaryWriter(tensorboard_dir)\n","%load_ext tensorboard\n","#%tensorboard --logdir runs/gated_experiment_1\n","\n","mode = Mode.train_gating\n","main(mode, writer)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"colab_train_gaiting.ipynb","provenance":[]},"interpreter":{"hash":"31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"metadata":{"interpreter":{"hash":"4cd7ab41f5fca4b9b44701077e38c5ffd31fe66a6cab21e0214b68d958d0e462"}}},"nbformat":4,"nbformat_minor":0}